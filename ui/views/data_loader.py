"""
ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸

CSVèª­ã¿è¾¼ã¿ / å–å¼•æ‰€APIã‹ã‚‰ã®ãƒ•ã‚§ãƒƒãƒ / ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã¯ã‚·ãƒ³ãƒœãƒ«åˆ¥ã« datasets ã«è“„ç©ã€‚
"""

import streamlit as st
import pandas as pd
from pathlib import Path

from data.csv_loader import TradingViewCSVLoader
from data.binance_loader import BinanceCSVLoader
from data.base import Timeframe, OHLCVData
from ui.components.chart import create_candlestick_chart


TIMEFRAMES = ["1m", "5m", "15m", "1h", "4h", "1d"]


def _detect_period_label(filename: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æœŸé–“ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡ºã™ã‚‹ã€‚

    ä¾‹:
        ETHUSDT-15m-20250201-20260130-merged.csv â†’ "20250201-20260130"
        ETHUSDT-15m-1y-merged.csv                â†’ "1y"
        ETHUSDT-15m-2025-02.csv                  â†’ "raw"
    """
    stem = Path(filename).stem
    parts = stem.split("-")
    # æ–°å½¢å¼: SYMBOL-TF-YYYYMMDD-YYYYMMDD-merged
    if (len(parts) >= 5 and parts[-1] == "merged"
            and len(parts[2]) == 8 and parts[2].isdigit()
            and len(parts[3]) == 8 and parts[3].isdigit()):
        return f"{parts[2]}-{parts[3]}"
    # æ—§å½¢å¼: SYMBOL-TF-LABEL-merged (e.g. 1y, prev1y)
    if len(parts) >= 4 and parts[-1] == "merged":
        return parts[2]
    return "raw"


def _add_to_datasets(ohlcv):
    """OHLCVDataã‚’ datasets ã«è¿½åŠ ï¼ˆã‚·ãƒ³ãƒœãƒ«åˆ¥ã«è“„ç©ï¼‰"""
    sym = getattr(ohlcv, "symbol", "UNKNOWN")
    tf_str = ohlcv.timeframe.value if hasattr(ohlcv, "timeframe") else "?"

    if sym not in st.session_state.datasets:
        st.session_state.datasets[sym] = {}
    st.session_state.datasets[sym][tf_str] = ohlcv

    # å¾Œæ–¹äº’æ›: ohlcv_dict ã¨ ohlcv_data ã‚‚æ›´æ–°
    st.session_state.ohlcv_dict[tf_str] = ohlcv
    st.session_state.ohlcv_data = ohlcv


def render_data_loader_page():
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‚’æç”»"""
    st.header("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
    st.caption("OHLCVãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    # ohlcv_dict ã®åˆæœŸåŒ– (å¾Œæ–¹äº’æ›)
    if "ohlcv_dict" not in st.session_state:
        st.session_state.ohlcv_dict = {}

    # èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€è¦§ï¼ˆãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã«è¡¨ç¤ºï¼‰
    if st.session_state.datasets:
        _render_datasets_summary()
        st.divider()

    tab_binance, tab_csv = st.tabs(["Binance CSV", "TradingView CSV"])

    with tab_binance:
        _render_binance_tab()

    with tab_csv:
        _render_csv_tab()

    # é¸æŠä¸­ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if st.session_state.datasets:
        _render_data_preview()


def _render_datasets_summary():
    """å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€è¦§"""
    st.subheader("ğŸ“¦ èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")

    datasets = st.session_state.datasets
    rows = []
    for sym, tf_dict in datasets.items():
        for tf_str, ohlcv in tf_dict.items():
            rows.append({
                "ã‚·ãƒ³ãƒœãƒ«": sym,
                "æ™‚é–“è¶³": tf_str,
                "ãƒ‡ãƒ¼ã‚¿æ•°": f"{ohlcv.bars:,}",
                "é–‹å§‹": str(ohlcv.start_time)[:19] if ohlcv.start_time else "",
                "çµ‚äº†": str(ohlcv.end_time)[:19] if ohlcv.end_time else "",
                "ã‚½ãƒ¼ã‚¹": getattr(ohlcv, "source", ""),
            })

    if rows:
        summary_df = pd.DataFrame(rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)

        # å€‹åˆ¥å‰Šé™¤
        col_del1, col_del2, col_del3 = st.columns([2, 2, 1])
        with col_del1:
            del_sym = st.selectbox(
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰Šé™¤",
                options=[""] + list(datasets.keys()),
                format_func=lambda x: "é¸æŠ..." if x == "" else x,
                key="del_dataset_sym",
            )
        with col_del2:
            if del_sym:
                st.caption(
                    f"{del_sym}: {', '.join(datasets[del_sym].keys())}"
                )
        with col_del3:
            if del_sym and st.button("ğŸ—‘ å‰Šé™¤", use_container_width=True):
                del st.session_state.datasets[del_sym]
                # ohlcv_dict ã‹ã‚‰ã‚‚è©²å½“ã‚·ãƒ³ãƒœãƒ«ã®TFã‚’å‰Šé™¤
                for tf_str in list(st.session_state.ohlcv_dict.keys()):
                    ohlcv = st.session_state.ohlcv_dict[tf_str]
                    if getattr(ohlcv, "symbol", "") == del_sym:
                        del st.session_state.ohlcv_dict[tf_str]
                st.rerun()


def _render_csv_tab():
    """CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¿ãƒ–ï¼ˆè¤‡æ•°TFå¯¾å¿œï¼‰"""
    st.subheader("TradingView CSV ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")

    symbol = st.text_input("ã‚·ãƒ³ãƒœãƒ«", value="", placeholder="WLDUSDT.P")

    st.markdown("**å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®CSVã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼ˆä¸è¦ãªTFã¯ç©ºã®ã¾ã¾ã§OKï¼‰**")

    loader = TradingViewCSVLoader()
    entries = []

    for tf_str in TIMEFRAMES:
        with st.expander(f"{tf_str}", expanded=False):
            col1, col2 = st.columns([3, 1])
            with col1:
                csv_path = st.text_input(
                    "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
                    placeholder=rf"C:\path\to\data_{tf_str}.csv",
                    key=f"csv_path_{tf_str}",
                )
            with col2:
                uploaded = st.file_uploader(
                    "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type=["csv"],
                    key=f"csv_upload_{tf_str}",
                )

            entries.append((tf_str, csv_path, uploaded))

    if st.button("CSVä¸€æ‹¬èª­ã¿è¾¼ã¿", type="primary", use_container_width=True):
        loaded_count = 0
        for tf_str, csv_path, uploaded in entries:
            try:
                ohlcv = _load_single_csv(
                    loader, tf_str, csv_path, uploaded, symbol
                )
                if ohlcv:
                    _add_to_datasets(ohlcv)
                    loaded_count += 1
            except Exception as e:
                st.error(f"[{tf_str}] Error: {e}")

        if loaded_count > 0:
            st.success(f"{loaded_count} ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å®Œäº†")
            st.rerun()
        else:
            st.warning("èª­ã¿è¾¼ã‚€CSVãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’å…¥åŠ›ã™ã‚‹ã‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


def _load_single_csv(loader, tf_str, csv_path, uploaded, symbol):
    """1ã¤ã®TFã®CSVã‚’èª­ã¿è¾¼ã‚€ã€‚å…¥åŠ›ãŒãªã‘ã‚Œã°None"""
    import tempfile
    import os

    tf = Timeframe.from_str(tf_str)

    if uploaded is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
            tmp.write(uploaded.getvalue())
            tmp_path = tmp.name
        sym = symbol or uploaded.name.replace(".csv", "")
        ohlcv = loader.load(tmp_path, symbol=sym, timeframe=tf)
        os.unlink(tmp_path)
        return ohlcv

    elif csv_path:
        sym = symbol or loader.detect_symbol_from_filename(csv_path)
        detected_tf = loader.detect_timeframe_from_filename(csv_path)
        if detected_tf:
            tf = detected_tf
        return loader.load(csv_path, symbol=sym, timeframe=tf)

    return None


def _detect_tf_from_data(df: pd.DataFrame):
    """OHLCVãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å·®åˆ†ã‹ã‚‰TFã‚’è‡ªå‹•åˆ¤å®š"""
    if "datetime" not in df.columns or len(df) < 3:
        return None
    diffs = df["datetime"].head(100).diff().dropna()
    if diffs.empty:
        return None
    mode_diff = diffs.mode().iloc[0]
    minutes = mode_diff.total_seconds() / 60
    tf_map = {
        1: Timeframe.M1, 5: Timeframe.M5, 15: Timeframe.M15,
        60: Timeframe.H1, 240: Timeframe.H4, 1440: Timeframe.D1,
    }
    closest = min(tf_map.keys(), key=lambda x: abs(x - minutes))
    return tf_map[closest]


def _render_binance_tab():
    """Binance Data CSV/ZIPã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä¸€æ‹¬èª­ã¿è¾¼ã¿å¯¾å¿œï¼‰"""
    st.subheader("Binance CSV/ZIP ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    st.caption("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®š or ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã§ä¸€æ‹¬èª­ã¿è¾¼ã¿ï¼ˆTFã¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•åˆ¤å®šï¼‰")

    loader = BinanceCSVLoader()

    # --- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³ ---
    col_dir, col_scan = st.columns([5, 1])
    with col_dir:
        dir_path = st.text_input(
            "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹",
            value="inputdata",
            key="binance_dir",
            help="CSV/ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹",
        )
    with col_scan:
        st.markdown("<br>", unsafe_allow_html=True)
        scan_clicked = st.button("ã‚¹ã‚­ãƒ£ãƒ³")

    if scan_clicked and dir_path:
        p = Path(dir_path)
        if not p.is_absolute():
            p = Path.cwd() / p
        if p.exists() and p.is_dir():
            files = sorted(list(p.glob("*.csv")) + list(p.glob("*.zip")))
            if files:
                # æœŸé–“ãƒ©ãƒ™ãƒ«ã‚’æ¤œå‡º
                period_labels = set()
                for f in files:
                    period_labels.add(_detect_period_label(f.name))
                st.session_state.binance_scan_files = [str(f) for f in files]
                st.session_state.binance_scan_periods = sorted(period_labels)
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                groups = {}
                for f in files:
                    sym = loader.detect_symbol(f.name)
                    if sym not in groups:
                        groups[sym] = []
                    groups[sym].append(str(f))
                st.session_state.binance_scan = groups
            else:
                st.warning("CSV/ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {p}")

    # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯¾å¿œï¼‰---
    uploaded = st.file_uploader(
        "ã¾ãŸã¯ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ï¼ˆè¤‡æ•°å¯ï¼‰",
        type=["csv", "zip"],
        accept_multiple_files=True,
        key="binance_multi_upload",
    )

    # --- æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ ---
    scan_periods = st.session_state.get("binance_scan_periods", [])
    scan_files = st.session_state.get("binance_scan_files", [])
    if scan_periods and len(scan_periods) > 1:
        selected_period = st.selectbox(
            "æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿",
            options=["ã™ã¹ã¦"] + scan_periods,
            index=0,
            key="binance_period_filter",
            help="åŒã˜ã‚·ãƒ³ãƒœãƒ«ãƒ»TFã§è¤‡æ•°æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€æœŸé–“ã‚’é¸æŠã—ã¦èª­ã¿è¾¼ã¿",
        )
        if selected_period != "ã™ã¹ã¦":
            filtered = [
                fp for fp in scan_files
                if _detect_period_label(Path(fp).name) == selected_period
            ]
            groups = {}
            for fp in filtered:
                sym = loader.detect_symbol(Path(fp).name)
                if sym not in groups:
                    groups[sym] = []
                groups[sym].append(fp)
            st.session_state.binance_scan = groups

    # --- ã‚¹ã‚­ãƒ£ãƒ³çµæœè¡¨ç¤ºï¼†ãƒ­ãƒ¼ãƒ‰ ---
    scan = st.session_state.get("binance_scan")
    if scan:
        total = sum(len(v) for v in scan.values())
        st.markdown(f"**{total} ãƒ•ã‚¡ã‚¤ãƒ« / {len(scan)} ã‚·ãƒ³ãƒœãƒ«æ¤œå‡º**")

        selected = st.multiselect(
            "èª­ã¿è¾¼ã‚€ã‚·ãƒ³ãƒœãƒ«",
            options=list(scan.keys()),
            default=list(scan.keys()),
            key="binance_syms",
        )

        if selected:
            rows = []
            for sym in selected:
                for fp in scan[sym]:
                    fname = Path(fp).name
                    tf = loader.detect_timeframe(fname)
                    rows.append({
                        "ã‚·ãƒ³ãƒœãƒ«": sym,
                        "ãƒ•ã‚¡ã‚¤ãƒ«": fname,
                        "æ™‚é–“è¶³ (å‚è€ƒ)": tf.value if tf else "?",
                    })
            st.dataframe(
                pd.DataFrame(rows), use_container_width=True, hide_index=True
            )
            st.caption("â€» TFã¯CSVãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰è‡ªå‹•åˆ¤å®šã—ã¾ã™ï¼ˆä¸Šè¨˜ã¯å‚è€ƒå€¤ï¼‰")

        col_load, col_clear = st.columns([3, 1])
        with col_load:
            if selected and st.button(
                "é¸æŠã‚’èª­ã¿è¾¼ã¿", type="primary", use_container_width=True
            ):
                _bulk_load_paths(loader, scan, selected)
        with col_clear:
            if st.button("ã‚¯ãƒªã‚¢", use_container_width=True):
                if "binance_scan" in st.session_state:
                    del st.session_state.binance_scan
                st.rerun()

    elif uploaded:
        st.markdown(f"**{len(uploaded)} ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¸ˆã¿**")
        if st.button(
            "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿", type="primary", use_container_width=True
        ):
            _bulk_load_uploads(loader, uploaded)


def _bulk_load_paths(loader, scan, selected_symbols):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³çµæœã‹ã‚‰ã®ä¸€æ‹¬èª­ã¿è¾¼ã¿"""
    files = []
    for sym in selected_symbols:
        files.extend(scan[sym])

    progress = st.progress(0, text="èª­ã¿è¾¼ã¿ä¸­...")
    loaded = 0
    errors = []

    for i, fp in enumerate(files):
        try:
            ohlcv = loader.load(fp)
            detected_tf = _detect_tf_from_data(ohlcv.df)
            if detected_tf:
                ohlcv.timeframe = detected_tf
            _add_to_datasets(ohlcv)
            loaded += 1
        except Exception as e:
            errors.append(f"[{Path(fp).name}] {e}")
        progress.progress((i + 1) / len(files), text=f"{i+1}/{len(files)}")

    progress.empty()
    for err in errors:
        st.error(err)
    if loaded:
        st.success(f"{loaded} ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        if "binance_scan" in st.session_state:
            del st.session_state.binance_scan
        st.rerun()


def _bulk_load_uploads(loader, uploaded_files):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ä¸€æ‹¬èª­ã¿è¾¼ã¿"""
    import tempfile
    import os

    progress = st.progress(0, text="èª­ã¿è¾¼ã¿ä¸­...")
    loaded = 0
    errors = []

    for i, uf in enumerate(uploaded_files):
        try:
            suffix = ".zip" if uf.name.endswith(".zip") else ".csv"
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                tmp.write(uf.getvalue())
                tmp_path = tmp.name

            sym = loader.detect_symbol(uf.name)
            ohlcv = loader.load(tmp_path, symbol=sym)
            os.unlink(tmp_path)

            detected_tf = _detect_tf_from_data(ohlcv.df)
            if detected_tf:
                ohlcv.timeframe = detected_tf
            _add_to_datasets(ohlcv)
            loaded += 1
        except Exception as e:
            errors.append(f"[{uf.name}] {e}")
        progress.progress(
            (i + 1) / len(uploaded_files), text=f"{i+1}/{len(uploaded_files)}"
        )

    progress.empty()
    for err in errors:
        st.error(err)
    if loaded:
        st.success(f"{loaded} ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        st.rerun()


def _render_data_preview():
    """é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
    st.divider()
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    datasets = st.session_state.datasets
    symbols = list(datasets.keys())

    # ã‚·ãƒ³ãƒœãƒ«é¸æŠ
    selected_sym = st.selectbox(
        "ã‚·ãƒ³ãƒœãƒ«",
        options=symbols,
        index=0,
        key="preview_symbol",
    )

    tf_dict = datasets[selected_sym]
    tfs = list(tf_dict.keys())

    # TFé¸æŠ
    selected_tf = st.selectbox(
        "ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ",
        options=tfs,
        index=0,
        key="preview_tf",
    )

    ohlcv = tf_dict[selected_tf]

    # åŸºæœ¬æƒ…å ±
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ã‚·ãƒ³ãƒœãƒ«", ohlcv.symbol)
    with col2:
        st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", f"{ohlcv.bars:,}")
    with col3:
        st.caption(f"é–‹å§‹: {str(ohlcv.start_time)[:19]}" if ohlcv.start_time else "")
    with col4:
        st.caption(f"çµ‚äº†: {str(ohlcv.end_time)[:19]}" if ohlcv.end_time else "")

    # ãƒãƒ£ãƒ¼ãƒˆ â€” ãƒ¬ãƒ³ã‚¸ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§é–‹å§‹ãƒ»çµ‚äº†ã‚’ä¸¡æ–¹é¸æŠå¯èƒ½
    last_idx = ohlcv.bars - 1
    default_start = max(0, ohlcv.bars - 500)

    bar_range = st.slider(
        "è¡¨ç¤ºç¯„å›²",
        min_value=0,
        max_value=last_idx,
        value=(default_start, last_idx),
        key="preview_bars",
        help="å·¦å³ã®ãƒãƒ³ãƒ‰ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦è¡¨ç¤ºç¯„å›²ã‚’é¸æŠ",
    )
    display_df = ohlcv.df.iloc[bar_range[0]:bar_range[1] + 1].copy()

    # é¸æŠç¯„å›²ã®æ—¥æ™‚ã‚’è¡¨ç¤º + åˆ‡ã‚Šå‡ºã—ãƒœã‚¿ãƒ³
    is_trimmed = bar_range[0] != 0 or bar_range[1] != last_idx
    if "datetime" in display_df.columns and not display_df.empty:
        range_start = str(display_df["datetime"].iloc[0])[:19]
        range_end = str(display_df["datetime"].iloc[-1])[:19]
        st.caption(f"é¸æŠç¯„å›²: {range_start} ã€œ {range_end}ï¼ˆ{len(display_df):,} æœ¬ï¼‰")

    if is_trimmed and "datetime" in display_df.columns and not display_df.empty:
        if st.button(
            f"âœ‚ï¸ ã“ã®ç¯„å›²ã§åˆ‡ã‚Šå‡ºã—ä¿å­˜ï¼ˆå…¨TFå¯¾è±¡ï¼‰",
            type="primary",
            use_container_width=True,
            help="é¸æŠã—ãŸæ—¥æ™‚ç¯„å›²ã§å…¨ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šå‡ºã—ã¦åˆ¥é€”ä¿å­˜ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›´ã—ã¾ã›ã‚“ï¼‰",
        ):
            _save_trimmed_dataset(
                selected_sym, tf_dict,
                display_df["datetime"].iloc[0],
                display_df["datetime"].iloc[-1],
            )

    fig = create_candlestick_chart(
        display_df,
        title=f"{ohlcv.symbol} - {selected_tf}",
    )
    st.plotly_chart(fig, use_container_width=True)

    # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
    with st.expander("ç”Ÿãƒ‡ãƒ¼ã‚¿"):
        st.dataframe(
            display_df.tail(100),
            use_container_width=True,
            hide_index=True,
        )

    # ä¿å­˜æ¸ˆã¿åˆ‡ã‚Šå‡ºã—ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
    _render_trimmed_datasets()


def _save_trimmed_dataset(symbol, tf_dict, start_dt, end_dt):
    """é¸æŠæ—¥æ™‚ç¯„å›²ã§å…¨TFã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šå‡ºã—ã¦ä¿å­˜"""
    MAX_TRIMMED = 20

    trimmed_data = {}
    for tf_str, ohlcv in tf_dict.items():
        if "datetime" not in ohlcv.df.columns:
            continue
        mask = (ohlcv.df["datetime"] >= start_dt) & (ohlcv.df["datetime"] <= end_dt)
        filtered_df = ohlcv.df.loc[mask].copy().reset_index(drop=True)
        if filtered_df.empty:
            continue
        trimmed_data[tf_str] = OHLCVData(
            df=filtered_df,
            symbol=ohlcv.symbol,
            timeframe=ohlcv.timeframe,
            source=getattr(ohlcv, "source", ""),
        )

    if not trimmed_data:
        st.error("æŒ‡å®šç¯„å›²ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    start_str = str(start_dt)[:10]
    end_str = str(end_dt)[:10]
    entry_id = f"{symbol}_{start_str}_{end_str}"
    label = f"{symbol}: {start_str} ~ {end_str}"

    # åŒã˜IDãŒã‚ã‚Œã°ä¸Šæ›¸ã
    trimmed_list = st.session_state.trimmed_datasets
    trimmed_list = [e for e in trimmed_list if e["id"] != entry_id]

    tf_summary = ", ".join(
        f"{tf}({d.bars:,})" for tf, d in trimmed_data.items()
    )

    trimmed_list.append({
        "id": entry_id,
        "symbol": symbol,
        "label": label,
        "start_dt": start_dt,
        "end_dt": end_dt,
        "data": trimmed_data,
    })

    # ä¸Šé™è¶…éæ™‚ã¯å¤ã„é †ã«å‰Šé™¤
    if len(trimmed_list) > MAX_TRIMMED:
        trimmed_list = trimmed_list[-MAX_TRIMMED:]

    st.session_state.trimmed_datasets = trimmed_list
    st.success(f"åˆ‡ã‚Šå‡ºã—ä¿å­˜: {label}ï¼ˆ{tf_summary}ï¼‰")
    st.rerun()


def _render_trimmed_datasets():
    """ä¿å­˜æ¸ˆã¿åˆ‡ã‚Šå‡ºã—ãƒ‡ãƒ¼ã‚¿ã®ä¸€è¦§"""
    trimmed_list = st.session_state.get("trimmed_datasets", [])
    if not trimmed_list:
        return

    st.divider()
    st.subheader("âœ‚ï¸ åˆ‡ã‚Šå‡ºã—ãƒ‡ãƒ¼ã‚¿")
    st.caption(f"{len(trimmed_list)} / 20 ä»¶ä¿å­˜æ¸ˆã¿ï¼ˆã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã§ä½¿ç”¨å¯èƒ½ï¼‰")

    rows = []
    for entry in trimmed_list:
        tfs = ", ".join(
            f"{tf}({d.bars:,})" for tf, d in entry["data"].items()
        )
        rows.append({
            "ã‚·ãƒ³ãƒœãƒ«": entry["symbol"],
            "æœŸé–“": f"{str(entry['start_dt'])[:10]} ~ {str(entry['end_dt'])[:10]}",
            "ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ": tfs,
        })

    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

    # å‰Šé™¤
    col_del1, col_del2 = st.columns([3, 1])
    with col_del1:
        del_options = [e["id"] for e in trimmed_list]
        del_target = st.selectbox(
            "å‰Šé™¤ã™ã‚‹åˆ‡ã‚Šå‡ºã—ãƒ‡ãƒ¼ã‚¿",
            options=[""] + del_options,
            format_func=lambda x: "é¸æŠ..." if x == "" else x,
            key="del_trimmed",
        )
    with col_del2:
        if del_target and st.button("ğŸ—‘ å‰Šé™¤", key="del_trimmed_btn", use_container_width=True):
            st.session_state.trimmed_datasets = [
                e for e in trimmed_list if e["id"] != del_target
            ]
            st.rerun()
