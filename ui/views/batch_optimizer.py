"""
ãƒãƒƒãƒæœ€é©åŒ–ãƒ“ãƒ¥ãƒ¼

inputdataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€
å…¨éŠ˜æŸ„ Ã— å…¨TF Ã— å…¨æœŸé–“ã®ãƒãƒƒãƒæœ€é©åŒ–ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
"""

import copy
import json
import re
import time
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import streamlit as st
import pandas as pd

from data.binance_loader import BinanceCSVLoader
from data.base import OHLCVData
from analysis.trend import TrendDetector, TrendRegime
from optimizer.grid import GridSearchOptimizer
from optimizer.genetic import GeneticOptimizer, GAConfig, GAResult
from optimizer.templates import BUILTIN_TEMPLATES
from optimizer.blacklist import get_blacklist, add_fail_to_blacklist
from optimizer.results import OptimizationResultSet, OptimizationEntry
from optimizer.validation import (
    DataSplitConfig,
    ValidatedResultSet,
    run_validated_optimization,
)
from optimizer.exit_profiles import (
    ATR_PROFILES,
    ATR_COMPACT_PROFILES,
    ATR_TRAILING_PROFILES,
    ATR_HYBRID_PROFILES,
    VWAP_PROFILES,
    BB_PROFILES,
    VWAP_TREND_PROFILES,
    VWAP_RANGE_PROFILES,
    ALL_PROFILES,
)


# =============================================================================
# å®šæ•°
# =============================================================================

PROJECT_DIR = Path(__file__).resolve().parent.parent.parent
INPUTDATA_DIR = PROJECT_DIR / "inputdata"
RESULTS_DIR = PROJECT_DIR / "results" / "batch"

# ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºè¨­å®š
TREND_METHOD = "ma_cross"
MA_FAST = 20
MA_SLOW = 50

# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®š
INITIAL_CAPITAL = 10000.0
COMMISSION_PCT = 0.04
SLIPPAGE_PCT = 0.0
TOP_N_RESULTS = 20

# OOSè¨­å®š
OOS_TRAIN_PCT = 0.6
OOS_VAL_PCT = 0.2
OOS_TOP_N_FOR_VAL = 10

TARGET_REGIMES = ["uptrend", "downtrend", "range"]


# =============================================================================
# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ—¥æœ¬èªåãƒãƒƒãƒ”ãƒ³ã‚°
# =============================================================================

TEMPLATE_LABELS: Dict[str, Tuple[str, str]] = {
    # (æ—¥æœ¬èªå, èª¬æ˜)
    # ãƒ­ãƒ³ã‚°ç³»
    "ma_crossover": ("MAã‚¯ãƒ­ã‚¹", "SMA fast/slow ã‚¯ãƒ­ã‚¹ã§ãƒ­ãƒ³ã‚°"),
    "rsi_reversal": ("RSIåç™º", "RSIå£²ã‚‰ã‚Œã™ãã‹ã‚‰ã®åç™º"),
    "bb_bounce": ("BBãƒã‚¦ãƒ³ã‚¹", "ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ä¸‹é™ã‚¿ãƒƒãƒ + RSIåç™º"),
    "macd_signal": ("MACDã‚·ã‚°ãƒŠãƒ«", "MACDãƒ©ã‚¤ãƒ³ãŒã‚·ã‚°ãƒŠãƒ«ã‚’ä¸ŠæŠœã‘"),
    "volume_spike": ("å‡ºæ¥é«˜æ€¥å¢—", "å‡ºæ¥é«˜æ€¥å¢— + é™°ç·šã‹ã‚‰ã®åè»¢"),
    "stochastic_reversal": ("ã‚¹ãƒˆã‚­ãƒ£ã‚¹åè»¢", "Stochastic K/D å£²ã‚‰ã‚Œã™ãã‚¯ãƒ­ã‚¹"),
    "trend_pullback_long": ("æŠ¼ã—ç›®è²·ã„", "ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã®æŠ¼ã—ç›®ã§ãƒ­ãƒ³ã‚°"),
    "vwap_touch_long": ("VWAPã‚¿ãƒƒãƒ", "VWAPãƒ©ã‚¤ãƒ³ã¸ã®æŠ¼ã—ç›®ã§ãƒ­ãƒ³ã‚°"),
    "vwap_upper1_long": ("VWAP+1Ïƒé †å¼µã‚Š", "VWAP+1Ïƒåˆ°é”ã§é †å¼µã‚Šãƒ­ãƒ³ã‚°"),
    "vwap_2sigma_long": ("VWAP-2Ïƒé€†å¼µã‚Š", "VWAP-2Ïƒã§é€†å¼µã‚Šãƒ­ãƒ³ã‚°"),
    # ã‚·ãƒ§ãƒ¼ãƒˆç³»
    "ma_crossover_short": ("MAã‚¯ãƒ­ã‚¹", "SMA fast/slow ä¸‹æŠœã‘ã§ã‚·ãƒ§ãƒ¼ãƒˆ"),
    "rsi_reversal_short": ("RSIåè½", "RSIè²·ã‚ã‚Œã™ãã‹ã‚‰ã®åè½"),
    "bb_bounce_short": ("BBãƒã‚¦ãƒ³ã‚¹", "ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ä¸Šé™ã‚¿ãƒƒãƒ + RSIé«˜"),
    "macd_signal_short": ("MACDã‚·ã‚°ãƒŠãƒ«", "MACDãƒ©ã‚¤ãƒ³ãŒã‚·ã‚°ãƒŠãƒ«ã‚’ä¸‹æŠœã‘"),
    "volume_spike_short": ("å‡ºæ¥é«˜æ€¥å¢—", "å‡ºæ¥é«˜æ€¥å¢— + é™½ç·šã‹ã‚‰ã®åè½"),
    "stochastic_reversal_short": ("ã‚¹ãƒˆã‚­ãƒ£ã‚¹åè»¢", "Stochastic K/D è²·ã‚ã‚Œã™ãã‚¯ãƒ­ã‚¹"),
    "trend_pullback_short": ("æˆ»ã‚Šå£²ã‚Š", "ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ã®æˆ»ã‚Šã§ã‚·ãƒ§ãƒ¼ãƒˆ"),
    "vwap_touch_short": ("VWAPã‚¿ãƒƒãƒ", "VWAPãƒ©ã‚¤ãƒ³ã¸ã®æˆ»ã‚Šã§ã‚·ãƒ§ãƒ¼ãƒˆ"),
    "vwap_lower1_short": ("VWAP-1Ïƒé †å¼µã‚Š", "VWAP-1Ïƒåˆ°é”ã§é †å¼µã‚Šã‚·ãƒ§ãƒ¼ãƒˆ"),
    "vwap_2sigma_short": ("VWAP+2Ïƒé€†å¼µã‚Š", "VWAP+2Ïƒã§é€†å¼µã‚Šã‚·ãƒ§ãƒ¼ãƒˆ"),
}


def get_template_label(name: str) -> str:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåã‹ã‚‰æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å–å¾—"""
    if name in TEMPLATE_LABELS:
        label, desc = TEMPLATE_LABELS[name]
        return f"{label} - {desc}"
    return name


# =============================================================================
# Exitæˆ¦ç•¥ã‚«ãƒ†ã‚´ãƒªå®šç¾©
# =============================================================================

EXIT_CATEGORIES: Dict[str, Dict[str, Any]] = {
    "atr_compact": {
        "label": "ATRã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆæ¨å¥¨ï¼‰",
        "description": "SL=ATRÃ—2.0å›ºå®šã€TP 3æŠï¼ˆ1.5/2.0/3.0ï¼‰",
        "profiles": ATR_COMPACT_PROFILES,
    },
    "atr": {
        "label": "ATRå›ºå®š",
        "description": "ATRå€ç‡ã§TP/SLå›ºå®š",
        "profiles": ATR_PROFILES,
    },
    "atr_trailing": {
        "label": "ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°",
        "description": "ATRãƒ™ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚° + ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
        "profiles": ATR_TRAILING_PROFILES,
    },
    "atr_hybrid": {
        "label": "ATRãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰",
        "description": "ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚° + ATR SL",
        "profiles": ATR_HYBRID_PROFILES,
    },
    "vwap": {
        "label": "VWAPç³»",
        "description": "VWAPãƒãƒ³ãƒ‰ã§TP",
        "profiles": VWAP_PROFILES + VWAP_TREND_PROFILES + VWAP_RANGE_PROFILES,
    },
    "bb": {
        "label": "BBç³»",
        "description": "BBãƒãƒ³ãƒ‰ã§TP",
        "profiles": BB_PROFILES,
    },
}


def get_exit_profile_label(profile: Dict[str, Any]) -> str:
    """Exit profileã‹ã‚‰æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å–å¾—"""
    name = profile.get("name", "unknown")

    # ATRå›ºå®šç³»
    if "atr_tp" in name and "trail" not in name:
        tp = profile.get("atr_tp_mult", 0)
        sl = profile.get("atr_sl_mult", 0)
        return f"TP={tp}Ã—ATR, SL={sl}Ã—ATR"

    # ATRãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ç³»ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
    if "trail" in name and "to" in name:
        trail = profile.get("atr_trailing_mult", 0)
        timeout = profile.get("timeout_bars", 0)
        return f"ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°{trail}Ã—ATR, ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ{timeout}bar"

    # ATRãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç³»
    if "trail" in name and "sl" in name and "to" not in name:
        trail = profile.get("atr_trailing_mult", 0)
        sl = profile.get("atr_sl_mult", 0)
        return f"ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°{trail}Ã—ATR + SL={sl}Ã—ATR"

    # VWAPç³»
    if "vwap" in name:
        if "trend" in name:
            trail = profile.get("atr_trailing_mult", 0)
            sl = profile.get("atr_sl_mult", 0)
            return f"VWAPãƒˆãƒ¬ãƒ³ãƒ‰: Trail{trail}Ã—ATR, SL={sl}Ã—ATR"
        elif "range" in name:
            band = profile.get("vwap_band", 0)
            sl = profile.get("atr_sl_mult", 0)
            tp_label = "VWAPãƒ©ã‚¤ãƒ³" if band == 0 else f"Â±{band}Ïƒ"
            return f"VWAPãƒ¬ãƒ³ã‚¸: TP={tp_label}, SL={sl}Ã—ATR"
        else:
            band = profile.get("vwap_band", 1)
            sl = profile.get("atr_sl_mult", 0)
            return f"TP=VWAPÂ±{band}Ïƒ, SL={sl}Ã—ATR"

    # BBç³»
    if "bb_exit" in name:
        sl = profile.get("atr_sl_mult", 0)
        return f"TP=BBãƒãƒ³ãƒ‰, SL={sl}Ã—ATR"

    return name


# =============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ£ãƒ³
# =============================================================================

def scan_inputdata() -> Dict[str, Any]:
    """
    inputdataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Returns:
        {
            "symbols": ["BTCUSDT", "ETHUSDT", ...],
            "timeframes": ["1m", "15m", "1h", "4h"],
            "periods": ["20240201-20250131", "20250201-20260130"],
            "files": {(symbol, tf, period): path, ...}
        }
    """
    if not INPUTDATA_DIR.exists():
        return {"symbols": [], "timeframes": [], "periods": [], "files": {}}

    symbols: Set[str] = set()
    timeframes: Set[str] = set()
    periods: Set[str] = set()
    files: Dict[Tuple[str, str, str], Path] = {}

    pattern = re.compile(r"^(.+?)-(\d+[mhd])-(\d{8}-\d{8})-merged\.csv$")

    for f in INPUTDATA_DIR.glob("*-merged.csv"):
        match = pattern.match(f.name)
        if match:
            symbol, tf, period = match.groups()
            symbols.add(symbol)
            timeframes.add(tf)
            periods.add(period)
            files[(symbol, tf, period)] = f

    # TFã‚’é †åºä»˜ãã§ã‚½ãƒ¼ãƒˆ
    tf_order = {"1m": 0, "5m": 1, "15m": 2, "30m": 3, "1h": 4, "4h": 5, "1d": 6}
    sorted_tfs = sorted(timeframes, key=lambda x: tf_order.get(x, 99))

    return {
        "symbols": sorted(symbols),
        "timeframes": sorted_tfs,
        "periods": sorted(periods),
        "files": files,
    }


def get_valid_tf_combos(
    selected_tfs: List[str],
    files: Dict[Tuple[str, str, str], Path],
    selected_symbols: List[str],
    selected_periods: List[str],
) -> List[Tuple[str, str]]:
    """
    é¸æŠã•ã‚ŒãŸTFã‹ã‚‰æœ‰åŠ¹ãªTFã‚³ãƒ³ãƒœï¼ˆå®Ÿè¡ŒTF, HTFï¼‰ã‚’ç”Ÿæˆ

    æ¡ä»¶:
    - å®Ÿè¡ŒTF < HTFï¼ˆæ™‚é–“è»¸ãŒå°ã•ã„æ–¹ãŒå®Ÿè¡ŒTFï¼‰
    - ä¸¡æ–¹ã®TFã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹éŠ˜æŸ„ãƒ»æœŸé–“ã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚‹
    """
    tf_order = {"1m": 0, "5m": 1, "15m": 2, "30m": 3, "1h": 4, "4h": 5, "1d": 6}

    combos = []
    for exec_tf in selected_tfs:
        for htf in selected_tfs:
            if tf_order.get(exec_tf, 99) < tf_order.get(htf, 99):
                # å°‘ãªãã¨ã‚‚1ã¤ã®éŠ˜æŸ„ãƒ»æœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
                has_data = False
                for symbol in selected_symbols:
                    for period in selected_periods:
                        if (symbol, exec_tf, period) in files and (symbol, htf, period) in files:
                            has_data = True
                            break
                    if has_data:
                        break
                if has_data:
                    combos.append((exec_tf, htf))

    return combos


def count_jobs(
    selected_symbols: List[str],
    selected_periods: List[str],
    tf_combos: List[Tuple[str, str]],
    files: Dict[Tuple[str, str, str], Path],
) -> int:
    """å®Ÿè¡Œã‚¸ãƒ§ãƒ–æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    count = 0
    for symbol in selected_symbols:
        for period in selected_periods:
            for exec_tf, htf in tf_combos:
                if (symbol, exec_tf, period) in files and (symbol, htf, period) in files:
                    count += 1
    return count


# =============================================================================
# ãƒãƒƒãƒå®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
# =============================================================================

def load_symbol_data(
    symbol: str,
    period: str,
    exec_tf: str,
    htf: str,
    files: Dict[Tuple[str, str, str], Path],
) -> Dict[str, OHLCVData]:
    """éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    loader = BinanceCSVLoader()
    tf_dict = {}

    exec_path = files.get((symbol, exec_tf, period))
    htf_path = files.get((symbol, htf, period))

    if exec_path:
        tf_dict[exec_tf] = loader.load(str(exec_path), symbol=symbol)
    if htf_path:
        tf_dict[htf] = loader.load(str(htf_path), symbol=symbol)

    return tf_dict


def prepare_exec_df(
    tf_dict: Dict[str, OHLCVData],
    exec_tf: str,
    htf: str,
    trend_method: str = "ma_cross",
    super_htf_df: Optional[pd.DataFrame] = None,
) -> pd.DataFrame:
    """å®Ÿè¡ŒTFã®DataFrameã«ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸"""
    exec_ohlcv = tf_dict[exec_tf]
    exec_df = exec_ohlcv.df.copy()

    if htf and htf in tf_dict:
        htf_ohlcv = tf_dict[htf]
        htf_df = htf_ohlcv.df.copy()
        detector = TrendDetector()

        if trend_method == "dual_tf_ema" and super_htf_df is not None:
            htf_df = detector.detect_dual_tf_ema(
                htf_df, super_htf_df, fast_period=MA_FAST, slow_period=MA_SLOW
            )
        else:
            htf_df = detector.detect_ma_cross(
                htf_df, fast_period=MA_FAST, slow_period=MA_SLOW
            )
        exec_df = TrendDetector.label_execution_tf(exec_df, htf_df)
    else:
        exec_df["trend_regime"] = TrendRegime.RANGE.value

    return exec_df


def generate_all_configs(
    selected_templates: List[str],
    selected_exit_profiles: List[Dict[str, Any]],
) -> List[Dict[str, Any]]:
    """é¸æŠã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ Ã— exit profiles ã® config ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    all_configs = []

    for tname in selected_templates:
        if tname not in BUILTIN_TEMPLATES:
            continue
        template = BUILTIN_TEMPLATES[tname]

        if selected_exit_profiles:
            configs = template.generate_configs(exit_profiles=selected_exit_profiles)
        else:
            configs = template.generate_configs()

        all_configs.extend(configs)

    return all_configs


def run_single_ga_optimization(
    exec_df: pd.DataFrame,
    templates: List[str],
    target_regimes: List[str],
    ga_config: GAConfig,
    symbol: str = "UNKNOWN",
    progress_callback=None,
    use_oos: bool = False,
    train_ratio: float = 0.8,
    use_blacklist: bool = True,
) -> List[GAResult]:
    """
    GAæœ€é©åŒ–ã‚’å®Ÿè¡Œï¼ˆOOSæ¤œè¨¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰

    Args:
        exec_df: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ãƒ™ãƒ«ä»˜ãã®DataFrame
        templates: ä½¿ç”¨ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåãƒªã‚¹ãƒˆ
        target_regimes: å¯¾è±¡ãƒ¬ã‚¸ãƒ¼ãƒ ãƒªã‚¹ãƒˆ
        ga_config: GAè¨­å®š
        symbol: éŠ˜æŸ„å
        progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        use_oos: OOSæ¤œè¨¼ã‚’è¡Œã†ã‹ã©ã†ã‹
        train_ratio: TrainæœŸé–“ã®å‰²åˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ80%ï¼‰
        use_blacklist: ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆå‚ç…§ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        List[GAResult]: å„ãƒ¬ã‚¸ãƒ¼ãƒ ã®GAçµæœãƒªã‚¹ãƒˆ
    """
    from optimizer.scoring import ScoringWeights

    # OOSç”¨ã«ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    n_rows = len(exec_df)
    if use_oos:
        split_idx = int(n_rows * train_ratio)
        train_df = exec_df.iloc[:split_idx].copy()
        test_df = exec_df.iloc[split_idx:].copy()
    else:
        train_df = exec_df
        test_df = None

    optimizer = GeneticOptimizer(
        templates=templates,
        ga_config=ga_config,
        scoring_weights=ScoringWeights(),
        initial_capital=INITIAL_CAPITAL,
        commission_pct=COMMISSION_PCT,
        slippage_pct=SLIPPAGE_PCT,
    )

    results = []
    total_regimes = len(target_regimes)

    for i, regime in enumerate(target_regimes):
        # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        if use_blacklist:
            blacklist = get_blacklist()
            filtered_templates = blacklist.filter_templates(templates, symbol, regime)

            if not filtered_templates:
                # å…¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆæ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                continue

            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ›´æ–°
            optimizer.templates = filtered_templates
        else:
            optimizer.templates = templates

        def ga_progress(gen, max_gen, desc):
            if progress_callback:
                base = i * ga_config.max_generations
                current = base + gen
                total = total_regimes * ga_config.max_generations
                progress_callback(current, total, f"GA [{regime}] ä¸–ä»£ {gen}/{max_gen}")

        # Trainãƒ‡ãƒ¼ã‚¿ã§GAæ¢ç´¢
        ga_result = optimizer.run(
            df=train_df,
            target_regime=regime,
            symbol=symbol,
            progress_callback=ga_progress,
        )

        # OOSæ¤œè¨¼: æœ€çµ‚å‹è€…ã‚’Testãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
        if use_oos and test_df is not None and ga_result.final_winner:
            winner = ga_result.final_winner
            train_pnl = winner.get("pnl", 0)

            # TestæœŸé–“ã§åŒã˜æˆ¦ç•¥ã‚’è©•ä¾¡
            from optimizer.genetic import Individual
            test_ind = Individual(
                template_name=winner["template"],
                params=winner["params"],
                generation=0,
            )

            try:
                config = test_ind.to_config()
                entry = optimizer._grid_optimizer._run_single(
                    df=test_df,
                    config=config,
                    template_name=test_ind.template_name,
                    params=test_ind.params,
                    target_regime=regime,
                    trend_column="trend_label",
                )
                test_pnl = entry.metrics.total_profit_pct
                test_trades = entry.metrics.total_trades
            except Exception:
                test_pnl = 0.0
                test_trades = 0

            # åˆ¤å®š: Test PnL > 0 ã‹ã¤ Train PnLã®30%ä»¥ä¸Šç¶­æŒã§PASS
            if test_pnl > 0 and (train_pnl <= 0 or test_pnl >= train_pnl * 0.3):
                verdict = "PASS"
            else:
                verdict = "FAIL"
                # FAILã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã«è‡ªå‹•ç™»éŒ²
                template_name = ga_result.final_winner.get("template", "")
                if template_name:
                    add_fail_to_blacklist(
                        symbol=symbol,
                        regime=regime,
                        template=template_name,
                        test_pnl=test_pnl,
                        train_pnl=train_pnl,
                    )

            # GAçµæœã«OOSæƒ…å ±ã‚’è¿½åŠ 
            ga_result.final_winner["train_pnl"] = train_pnl
            ga_result.final_winner["test_pnl"] = test_pnl
            ga_result.final_winner["test_trades"] = test_trades
            ga_result.final_winner["verdict"] = verdict

        results.append(ga_result)

    return results


def run_single_optimization(
    exec_df: pd.DataFrame,
    all_configs: List[Dict[str, Any]],
    use_oos: bool,
    n_workers: int,
    target_regimes: List[str] = None,
    progress_callback=None,
    adaptive_config: Optional["AdaptiveSearchConfig"] = None,
) -> Any:
    """
    å˜ä¸€éŠ˜æŸ„ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œ

    Args:
        adaptive_config: é©å¿œå‹æ¢ç´¢ã®è¨­å®šï¼ˆNoneã®å ´åˆã¯å¾“æ¥ã®ç·å½“ãŸã‚Šï¼‰
    """
    from optimizer.adaptive import AdaptiveSearchConfig

    if target_regimes is None:
        target_regimes = TARGET_REGIMES

    optimizer = GridSearchOptimizer(
        initial_capital=INITIAL_CAPITAL,
        commission_pct=COMMISSION_PCT,
        slippage_pct=SLIPPAGE_PCT,
        top_n_results=TOP_N_RESULTS,
    )

    configs = copy.deepcopy(all_configs)

    # é©å¿œå‹æ¢ç´¢ãŒæœ‰åŠ¹ãªå ´åˆ
    if adaptive_config is not None:
        # é©å¿œå‹æ¢ç´¢ã¯OOSæ¤œè¨¼ã¨çµ„ã¿åˆã‚ã›ãªã„ï¼ˆScoutã§ååˆ†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        adaptive_result = optimizer.run_adaptive(
            df=exec_df,
            configs=configs,
            target_regimes=target_regimes,
            adaptive_config=adaptive_config,
            n_workers=n_workers,
            progress_callback=progress_callback,
        )
        # äº’æ›æ€§ã®ãŸã‚OptimizationResultSetã‚’è¿”ã™
        return adaptive_result.final_result

    # å¾“æ¥ã®ç·å½“ãŸã‚Šæ¢ç´¢
    if use_oos:
        split_config = DataSplitConfig(
            train_pct=OOS_TRAIN_PCT,
            val_pct=OOS_VAL_PCT,
            top_n_for_val=OOS_TOP_N_FOR_VAL,
        )
        result = run_validated_optimization(
            df=exec_df,
            all_configs=configs,
            target_regimes=target_regimes,
            split_config=split_config,
            optimizer=optimizer,
            n_workers=n_workers,
            progress_callback=progress_callback,
        )
    else:
        result = optimizer.run(
            df=exec_df,
            configs=configs,
            target_regimes=target_regimes,
            n_workers=n_workers,
            progress_callback=progress_callback,
        )

    return result


def save_batch_result(
    result: Any,
    symbol: str,
    period: str,
    exec_tf: str,
    htf: str,
    use_oos: bool,
    output_dir: Path,
) -> Path:
    """æœ€é©åŒ–çµæœã‚’JSONã§ä¿å­˜"""
    def _safe_float(v: float) -> float:
        import math
        if math.isinf(v) or math.isnan(v):
            return 9999.0 if v > 0 else -9999.0 if v < 0 else 0.0
        return v

    def _entry_to_dict(e: OptimizationEntry) -> Dict[str, Any]:
        return {
            "template": e.template_name,
            "params": e.params,
            "regime": e.trend_regime,
            "exit_profile": e.config.get("_exit_profile", "default"),
            "score": round(_safe_float(e.composite_score), 4),
            "metrics": {
                "trades": e.metrics.total_trades,
                "win_rate": round(_safe_float(e.metrics.win_rate), 1),
                "profit_factor": round(_safe_float(e.metrics.profit_factor), 2),
                "total_pnl": round(_safe_float(e.metrics.total_profit_pct), 2),
                "max_dd": round(_safe_float(e.metrics.max_drawdown_pct), 2),
                "sharpe": round(_safe_float(e.metrics.sharpe_ratio), 2),
            },
        }

    data: Dict[str, Any] = {
        "symbol": symbol,
        "period": period,
        "execution_tf": exec_tf,
        "htf": htf,
        "oos": use_oos,
    }

    if use_oos and isinstance(result, ValidatedResultSet):
        data["train_results"] = [
            _entry_to_dict(e)
            for e in result.train_results.ranked()[:TOP_N_RESULTS]
        ]
        data["test_results"] = {}
        for regime, entry in result.test_results.items():
            data["test_results"][regime] = _entry_to_dict(entry)
        data["val_best"] = {}
        for regime, entry in result.val_best.items():
            data["val_best"][regime] = _entry_to_dict(entry)
        data["warnings"] = result.overfitting_warnings
        data["total_combinations"] = result.train_results.total_combinations
    else:
        result_set = result
        data["total_combinations"] = result_set.total_combinations
        data["results"] = [
            _entry_to_dict(e)
            for e in result_set.ranked()[:TOP_N_RESULTS]
        ]

    fname = f"{symbol}_{period}_{exec_tf}_{htf}.json"
    json_path = output_dir / fname
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return json_path


# =============================================================================
# ãƒãƒƒãƒãƒ“ãƒ¥ãƒ¼UI
# =============================================================================

def render_batch_view():
    """ãƒãƒƒãƒæœ€é©åŒ–ãƒ“ãƒ¥ãƒ¼ã‚’æç”»"""
    st.subheader("ğŸš€ ãƒãƒƒãƒæœ€é©åŒ–")
    st.caption("inputdataã‹ã‚‰å…¨éŠ˜æŸ„Ã—å…¨TFÃ—å…¨æœŸé–“ã‚’ä¸€æ‹¬æœ€é©åŒ–")

    # GAæ¡ç”¨å€™è£œã‹ã‚‰ã®è¨­å®šãŒã‚ã‚‹å ´åˆã¯é€šçŸ¥
    if st.session_state.get("batch_from_ga_candidates"):
        candidates = st.session_state.get("ga_adopted_candidates", {})
        source = candidates.get("source", "")
        symbols = candidates.get("symbols", [])
        templates = candidates.get("templates", [])

        st.info(f"ğŸ¯ **GAæ¡ç”¨å€™è£œã‹ã‚‰ã®è¨­å®š** (ã‚½ãƒ¼ã‚¹: {source})\n\n"
                f"éŠ˜æŸ„: {len(symbols)}ç¨® | ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(templates)}ç¨®")

        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("âŒ è¨­å®šã‚’ã‚¯ãƒªã‚¢", key="clear_ga_candidates"):
                st.session_state.batch_from_ga_candidates = False
                st.session_state.ga_adopted_candidates = {}
                st.rerun()

    # ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ£ãƒ³
    scan_result = scan_inputdata()

    if not scan_result["symbols"]:
        st.warning("ğŸ“‚ inputdataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        st.info(f"ãƒ‘ã‚¹: `{INPUTDATA_DIR}`")
        return

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    if "batch_running" not in st.session_state:
        st.session_state.batch_running = False
    if "batch_progress" not in st.session_state:
        st.session_state.batch_progress = {"current": 0, "total": 0, "status": ""}

    # å®Ÿè¡Œä¸­ã®å ´åˆã¯é€²æ—è¡¨ç¤º
    if st.session_state.batch_running:
        _render_batch_progress()
        return

    # --- ãƒ‡ãƒ¼ã‚¿é¸æŠ ---
    with st.expander("ğŸ“¦ ãƒ‡ãƒ¼ã‚¿é¸æŠ", expanded=True):
        _render_data_selection(scan_result)

    # --- ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  ---
    with st.expander("â±ï¸ ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ", expanded=True):
        _render_timeframe_selection(scan_result)

    # --- æˆ¦ç•¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ---
    with st.expander("ğŸ¯ æˆ¦ç•¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", expanded=True):
        _render_template_selection()

    # --- Exitæˆ¦ç•¥ ---
    with st.expander("ğŸšª Exitæˆ¦ç•¥", expanded=True):
        _render_exit_selection()

    # --- å®Ÿè¡Œè¨­å®š ---
    with st.expander("âš™ï¸ å®Ÿè¡Œè¨­å®š", expanded=True):
        _render_execution_settings()

    # --- å®Ÿè¡Œã‚µãƒãƒªãƒ¼ ---
    _render_execution_summary(scan_result)

    # --- è‡ªå‹•å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ï¼ˆGAå€™è£œã‹ã‚‰ã®é·ç§»æ™‚ï¼‰ ---
    if st.session_state.get("batch_auto_start"):
        st.session_state.batch_auto_start = False  # ãƒ•ãƒ©ã‚°ã‚¯ãƒªã‚¢
        st.info("ğŸš€ GAæ¡ç”¨å€™è£œã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚’è‡ªå‹•é–‹å§‹ã—ã¾ã™...")
        _start_batch_optimization(scan_result)
        return

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
    st.divider()

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        is_running = st.session_state.get("batch_running", False)
        btn_label = "â³ å®Ÿè¡Œä¸­..." if is_running else "ğŸš€ ãƒãƒƒãƒæœ€é©åŒ–ã‚’å®Ÿè¡Œ"
        if st.button(
            btn_label,
            type="primary",
            use_container_width=True,
            disabled=is_running,
        ):
            _start_batch_optimization(scan_result)


def _render_data_selection(scan_result: Dict[str, Any]):
    """ãƒ‡ãƒ¼ã‚¿é¸æŠUIã‚’æç”»"""
    # æœŸé–“é¸æŠ
    st.markdown("**æœŸé–“**")
    periods = scan_result["periods"]

    # æœŸé–“ã‹ã‚‰å¹´ã‚’æŠ½å‡ºã—ã¦ãƒ©ãƒ™ãƒ«åŒ–
    period_labels = {}
    for p in periods:
        start_year = p[:4]
        end_year = p[9:13]
        if start_year == end_year:
            period_labels[p] = f"{start_year}å¹´"
        else:
            period_labels[p] = f"{start_year}-{end_year}å¹´"

    cols = st.columns(len(periods))
    selected_periods = []
    for i, period in enumerate(periods):
        with cols[i]:
            if st.checkbox(
                period_labels[period],
                value=True,
                key=f"batch_period_{period}",
            ):
                selected_periods.append(period)

    st.session_state.batch_selected_periods = selected_periods

    # éŠ˜æŸ„é¸æŠ
    st.markdown("**éŠ˜æŸ„**")
    symbols = scan_result["symbols"]

    col1, col2, col3 = st.columns([1, 1, 4])
    with col1:
        if st.button("å…¨é¸æŠ", key="batch_select_all_symbols", use_container_width=True):
            for sym in symbols:
                st.session_state[f"batch_symbol_{sym}"] = True
            st.rerun()
    with col2:
        if st.button("å…¨è§£é™¤", key="batch_deselect_all_symbols", use_container_width=True):
            for sym in symbols:
                st.session_state[f"batch_symbol_{sym}"] = False
            st.rerun()

    # éŠ˜æŸ„ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼ˆã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºï¼‰
    n_cols = 6
    selected_symbols = []
    rows = [symbols[i:i + n_cols] for i in range(0, len(symbols), n_cols)]

    # GAæ¡ç”¨å€™è£œã‹ã‚‰ã®éŠ˜æŸ„ãƒªã‚¹ãƒˆ
    ga_candidates = st.session_state.get("ga_adopted_candidates", {})
    ga_symbols = ga_candidates.get("symbols", [])
    from_ga = st.session_state.get("batch_from_ga_candidates", False)

    for row in rows:
        cols = st.columns(n_cols)
        for i, sym in enumerate(row):
            with cols[i]:
                # GAæ¡ç”¨å€™è£œãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã€å€™è£œã®éŠ˜æŸ„ã ã‘ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON
                if from_ga and ga_symbols:
                    default_val = sym in ga_symbols
                else:
                    default_val = st.session_state.get(f"batch_symbol_{sym}", True)
                if st.checkbox(
                    sym.replace("USDT", ""),
                    value=default_val,
                    key=f"batch_symbol_{sym}",
                ):
                    selected_symbols.append(sym)

    st.session_state.batch_selected_symbols = selected_symbols
    ga_info = f" (GAå€™è£œ: {len(ga_symbols)})" if from_ga and ga_symbols else ""
    st.caption(f"é¸æŠä¸­: {len(selected_symbols)} / {len(symbols)} éŠ˜æŸ„{ga_info}")


def _render_timeframe_selection(scan_result: Dict[str, Any]):
    """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é¸æŠUIã‚’æç”»"""
    st.markdown("**å®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ** (å°ã•ã„æ–¹ãŒå®Ÿè¡ŒTFã€å¤§ãã„æ–¹ãŒHTFã«ãªã‚Šã¾ã™)")
    st.caption("âš ï¸ 1mã¯å‡¦ç†ãŒé‡ã„ãŸã‚ã€å¿…è¦ãªå ´åˆã®ã¿é¸æŠã—ã¦ãã ã•ã„")

    timeframes = scan_result["timeframes"]

    cols = st.columns(len(timeframes))
    selected_tfs = []
    for i, tf in enumerate(timeframes):
        with cols[i]:
            # 1m, 4hã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFF
            default_val = tf not in ("1m", "4h")
            if st.checkbox(
                tf,
                value=st.session_state.get(f"batch_tf_{tf}", default_val),
                key=f"batch_tf_{tf}",
            ):
                selected_tfs.append(tf)

    st.session_state.batch_selected_tfs = selected_tfs

    # æœ‰åŠ¹ãªTFã‚³ãƒ³ãƒœã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
    files = scan_result["files"]
    selected_symbols = st.session_state.get("batch_selected_symbols", [])
    selected_periods = st.session_state.get("batch_selected_periods", [])

    tf_combos = get_valid_tf_combos(selected_tfs, files, selected_symbols, selected_periods)
    st.session_state.batch_tf_combos = tf_combos

    if tf_combos:
        combo_strs = [f"{e}/{h}" for e, h in tf_combos]
        st.success(f"âœ… æœ‰åŠ¹ãªTFã‚³ãƒ³ãƒœ: {', '.join(combo_strs)}")
    else:
        st.warning("âš ï¸ æœ‰åŠ¹ãªTFã‚³ãƒ³ãƒœãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆ2ã¤ä»¥ä¸Šã®TFã‚’é¸æŠã—ã¦ãã ã•ã„ï¼‰")


def _render_template_selection():
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¸æŠUIã‚’æç”»"""
    # ãƒœã‚¿ãƒ³è¡Œ
    col1, col2, col3, col4 = st.columns([1, 1, 1, 3])
    with col1:
        if st.button("å…¨é¸æŠ", key="batch_select_all_templates", use_container_width=True):
            for tname in BUILTIN_TEMPLATES:
                st.session_state[f"batch_template_{tname}"] = True
            st.rerun()
    with col2:
        if st.button("å…¨è§£é™¤", key="batch_deselect_all_templates", use_container_width=True):
            for tname in BUILTIN_TEMPLATES:
                st.session_state[f"batch_template_{tname}"] = False
            st.rerun()
    with col3:
        if st.button("ãƒ­ãƒ³ã‚°ã®ã¿", key="batch_long_only", use_container_width=True):
            for tname in BUILTIN_TEMPLATES:
                st.session_state[f"batch_template_{tname}"] = "short" not in tname
            st.rerun()
    with col4:
        if st.button("ã‚·ãƒ§ãƒ¼ãƒˆã®ã¿", key="batch_short_only", use_container_width=True):
            for tname in BUILTIN_TEMPLATES:
                st.session_state[f"batch_template_{tname}"] = "short" in tname
            st.rerun()

    # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã”ã¨ã®ä»¶æ•°ã‚’å–å¾—
    blacklist = get_blacklist()
    bl_summary = blacklist.summary()
    bl_by_template = bl_summary.get("by_template", {})

    # GAæ¡ç”¨å€™è£œã‹ã‚‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
    ga_candidates = st.session_state.get("ga_adopted_candidates", {})
    ga_templates = ga_candidates.get("templates", [])
    from_ga = st.session_state.get("batch_from_ga_candidates", False)

    # ãƒ­ãƒ³ã‚°ç³»
    st.markdown("**ğŸ“ˆ ãƒ­ãƒ³ã‚°ç³»**")
    long_templates = [t for t in BUILTIN_TEMPLATES if "short" not in t]
    selected_templates = []

    for tname in long_templates:
        label = get_template_label(tname)
        bl_count = bl_by_template.get(tname, 0)
        if bl_count > 0:
            label = f"{label} (BL: {bl_count})"
        # GAæ¡ç”¨å€™è£œãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã€å€™è£œã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã ã‘ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON
        if from_ga and ga_templates:
            default_val = tname in ga_templates
        else:
            default_val = st.session_state.get(f"batch_template_{tname}", True)
        if st.checkbox(
            label,
            value=default_val,
            key=f"batch_template_{tname}",
        ):
            selected_templates.append(tname)

    # ã‚·ãƒ§ãƒ¼ãƒˆç³»
    st.markdown("**ğŸ“‰ ã‚·ãƒ§ãƒ¼ãƒˆç³»**")
    short_templates = [t for t in BUILTIN_TEMPLATES if "short" in t]

    for tname in short_templates:
        label = get_template_label(tname)
        bl_count = bl_by_template.get(tname, 0)
        if bl_count > 0:
            label = f"{label} (BL: {bl_count})"
        # GAæ¡ç”¨å€™è£œãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã€å€™è£œã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã ã‘ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON
        if from_ga and ga_templates:
            default_val = tname in ga_templates
        else:
            default_val = st.session_state.get(f"batch_template_{tname}", True)
        if st.checkbox(
            label,
            value=default_val,
            key=f"batch_template_{tname}",
        ):
            selected_templates.append(tname)

    st.session_state.batch_selected_templates = selected_templates

    # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåˆè¨ˆã‚‚è¡¨ç¤º
    total_bl = bl_summary.get("total", 0)
    bl_info = f" | BLåˆè¨ˆ: {total_bl}ä»¶" if total_bl > 0 else ""
    ga_info = f" | GAå€™è£œ: {len(ga_templates)}" if from_ga and ga_templates else ""
    st.caption(f"é¸æŠä¸­: {len(selected_templates)} / {len(BUILTIN_TEMPLATES)} ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ{bl_info}{ga_info}")


def _render_exit_selection():
    """Exitæˆ¦ç•¥é¸æŠUIã‚’æç”»"""
    selected_profiles = []

    for cat_key, cat_info in EXIT_CATEGORIES.items():
        profiles = cat_info["profiles"]
        label = cat_info["label"]
        desc = cat_info["description"]

        # ã‚«ãƒ†ã‚´ãƒªãƒ˜ãƒƒãƒ€ãƒ¼
        col1, col2, col3, col4 = st.columns([3, 1, 1, 2])
        with col1:
            st.markdown(f"**{label}** ({len(profiles)}) - {desc}")
        with col2:
            if st.button("å…¨ON", key=f"batch_exit_cat_on_{cat_key}", use_container_width=True):
                for p in profiles:
                    st.session_state[f"batch_exit_{p['name']}"] = True
                st.rerun()
        with col3:
            if st.button("å…¨OFF", key=f"batch_exit_cat_off_{cat_key}", use_container_width=True):
                for p in profiles:
                    st.session_state[f"batch_exit_{p['name']}"] = False
                st.rerun()

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆæœ€å¤§5è¡Œè¡¨ç¤ºã€ãã‚Œä»¥ä¸Šã¯æŠ˜ã‚ŠãŸãŸã¿ï¼‰
        show_all = len(profiles) <= 5
        display_profiles = profiles if show_all else profiles[:3]

        for p in display_profiles:
            pname = p["name"]
            plabel = get_exit_profile_label(p)
            default_val = st.session_state.get(f"batch_exit_{pname}", True)
            if st.checkbox(
                plabel,
                value=default_val,
                key=f"batch_exit_{pname}",
            ):
                selected_profiles.append(p)

        if not show_all:
            with st.expander(f"ã•ã‚‰ã« {len(profiles) - 3} ä»¶ã‚’è¡¨ç¤º"):
                for p in profiles[3:]:
                    pname = p["name"]
                    plabel = get_exit_profile_label(p)
                    default_val = st.session_state.get(f"batch_exit_{pname}", True)
                    if st.checkbox(
                        plabel,
                        value=default_val,
                        key=f"batch_exit_{pname}",
                    ):
                        selected_profiles.append(p)

        st.divider()

    st.session_state.batch_selected_exit_profiles = selected_profiles
    total_profiles = sum(len(c["profiles"]) for c in EXIT_CATEGORIES.values())
    st.caption(f"é¸æŠä¸­: {len(selected_profiles)} / {total_profiles} Exitæˆ¦ç•¥")


def _render_execution_settings():
    """å®Ÿè¡Œè¨­å®šUIã‚’æç”»"""
    # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºæ–¹æ³•
    st.markdown("**ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºæ–¹æ³•**")
    trend_col1, trend_col2 = st.columns(2)
    with trend_col1:
        batch_trend_method = st.selectbox(
            "æ¤œå‡ºæ–¹æ³•",
            options=["ma_cross", "dual_tf_ema", "adx", "combined"],
            format_func=lambda x: {
                "ma_cross": "MA Crossï¼ˆç§»å‹•å¹³å‡ã‚¯ãƒ­ã‚¹ï¼‰",
                "dual_tf_ema": "Dual-TF EMAï¼ˆ4h+1håˆæ„ï¼‰â˜…æ¨å¥¨",
                "adx": "ADXï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼‰",
                "combined": "MA Cross + ADXï¼ˆè¤‡åˆï¼‰",
            }[x],
            index=1,
            key="batch_trend_method",
            help="ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¬ãƒ³ã‚¸ã‚’åˆ¤å®šã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
        )
    with trend_col2:
        if batch_trend_method == "dual_tf_ema":
            batch_super_htf = st.selectbox(
                "Super HTF",
                options=["4h", "1d"],
                index=0,
                key="batch_super_htf",
                help="Dual-TF EMAã®ä¸Šä½ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆé€šå¸¸4hï¼‰",
            )
        else:
            batch_super_htf = None

    st.session_state.batch_trend_method = batch_trend_method
    st.session_state.batch_super_htf = batch_super_htf

    st.divider()

    # ãƒ¬ã‚¸ãƒ¼ãƒ é¸æŠ
    st.markdown("**å¯¾è±¡ãƒ¬ã‚¸ãƒ¼ãƒ **")
    regime_cols = st.columns(3)
    selected_regimes = []

    with regime_cols[0]:
        if st.checkbox(
            "ğŸ“ˆ Uptrend",
            value=st.session_state.get("batch_regime_uptrend", True),
            key="batch_regime_uptrend",
        ):
            selected_regimes.append("uptrend")

    with regime_cols[1]:
        if st.checkbox(
            "ğŸ“‰ Downtrend",
            value=st.session_state.get("batch_regime_downtrend", True),
            key="batch_regime_downtrend",
        ):
            selected_regimes.append("downtrend")

    with regime_cols[2]:
        if st.checkbox(
            "â†”ï¸ Range",
            value=st.session_state.get("batch_regime_range", True),
            key="batch_regime_range",
        ):
            selected_regimes.append("range")

    st.session_state.batch_selected_regimes = selected_regimes

    st.divider()

    # ãã®ä»–ã®è¨­å®š
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        use_oos = st.checkbox(
            "OOSæ¤œè¨¼",
            value=st.session_state.get("batch_use_oos", True),
            key="batch_use_oos",
            help="Train 60% / Val 20% / Test 20% ã®3åˆ†å‰²æ¤œè¨¼",
        )

    with col2:
        use_blacklist = st.checkbox(
            "ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆå‚ç…§",
            value=st.session_state.get("batch_use_blacklist", True),
            key="batch_use_blacklist",
            help="éå»ã«FAILã—ãŸçµ„ã¿åˆã‚ã›ã‚’ã‚¹ã‚­ãƒƒãƒ—",
        )

    with col3:
        n_workers = st.selectbox(
            "ä¸¦åˆ—æ•°",
            options=[1, 2, 4, 8],
            index=2,
            key="batch_n_workers",
        )

    with col4:
        reuse_existing = st.checkbox(
            "æ—¢å­˜çµæœã‚’å†åˆ©ç”¨",
            value=st.session_state.get("batch_reuse_existing", True),
            key="batch_reuse_existing",
            help="åŒã˜æ¡ä»¶ã®çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—",
        )

    # æ¢ç´¢æ–¹æ³•ã®é¸æŠ
    st.divider()
    st.markdown("### ğŸ” æ¢ç´¢æ–¹æ³•")

    search_method = st.radio(
        "æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
        ["grid", "ga"],
        format_func=lambda x: {
            "grid": "ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆå…¨çµ„ã¿åˆã‚ã›ï¼‰",
            "ga": "ğŸ§¬ éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆåŠ¹ç‡çš„æ¢ç´¢ï¼‰",
        }[x],
        index=st.session_state.get("batch_search_method_idx", 0),
        key="batch_search_method",
        horizontal=True,
    )
    st.session_state["batch_search_method_idx"] = 0 if search_method == "grid" else 1

    if search_method == "ga":
        st.info("ğŸ’¡ GAã¯å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã‚’è©¦ã•ãšã€é€²åŒ–çš„ã«è‰¯ã„è§£ã‚’æ¢ç´¢ã€‚ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®1/3ã€œ1/5ã®è©•ä¾¡å›æ•°ã§æ¸ˆã¿ã¾ã™ã€‚")

        ga_col1, ga_col2, ga_col3, ga_col4 = st.columns(4)
        with ga_col1:
            ga_population = st.number_input(
                "é›†å›£ã‚µã‚¤ã‚º",
                value=st.session_state.get("batch_ga_population", 20),
                min_value=10,
                max_value=100,
                step=5,
                key="batch_ga_population",
                help="1ä¸–ä»£ã‚ãŸã‚Šã®å€‹ä½“æ•°",
            )
        with ga_col2:
            ga_generations = st.number_input(
                "æœ€å¤§ä¸–ä»£æ•°",
                value=st.session_state.get("batch_ga_generations", 10),
                min_value=5,
                max_value=50,
                step=5,
                key="batch_ga_generations",
                help="é€²åŒ–ã‚’ç¹°ã‚Šè¿”ã™æœ€å¤§å›æ•°",
            )
        with ga_col3:
            ga_elite_ratio = st.slider(
                "ã‚¨ãƒªãƒ¼ãƒˆç‡",
                0.1, 0.5, st.session_state.get("batch_ga_elite", 0.25), 0.05,
                key="batch_ga_elite",
                help="æ¬¡ä¸–ä»£ã«å¼•ãç¶™ãä¸Šä½å€‹ä½“ã®å‰²åˆ",
            )
        with ga_col4:
            ga_mutation_rate = st.slider(
                "çªç„¶å¤‰ç•°ç‡",
                0.05, 0.3, st.session_state.get("batch_ga_mutation", 0.15), 0.05,
                key="batch_ga_mutation",
                help="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰åŒ–ã•ã›ã‚‹ç¢ºç‡",
            )


def _render_execution_summary(scan_result: Dict[str, Any]):
    """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’æç”»"""
    st.markdown("### ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼")

    selected_symbols = st.session_state.get("batch_selected_symbols", [])
    selected_periods = st.session_state.get("batch_selected_periods", [])
    tf_combos = st.session_state.get("batch_tf_combos", [])
    selected_templates = st.session_state.get("batch_selected_templates", [])
    selected_exit_profiles = st.session_state.get("batch_selected_exit_profiles", [])

    files = scan_result["files"]
    n_jobs = count_jobs(selected_symbols, selected_periods, tf_combos, files)

    # configæ•°ã®è¨ˆç®—
    n_templates = len(selected_templates)
    n_exits = len(selected_exit_profiles) if selected_exit_profiles else 1
    n_configs = n_templates * n_exits * 3  # 3 = ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã®æ¦‚ç®—

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("éŠ˜æŸ„", len(selected_symbols))
    with col2:
        st.metric("TFã‚³ãƒ³ãƒœ", len(tf_combos))
    with col3:
        st.metric("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", n_templates)
    with col4:
        st.metric("Exitæˆ¦ç•¥", n_exits)

    st.info(f"ğŸ“Œ **æ¨å®šã‚¸ãƒ§ãƒ–æ•°: {n_jobs}** ({len(selected_symbols)}éŠ˜æŸ„ Ã— {len(tf_combos)}TF Ã— {len(selected_periods)}æœŸé–“)")


def _render_batch_progress():
    """ãƒãƒƒãƒå®Ÿè¡Œä¸­ã®é€²æ—è¡¨ç¤º"""
    progress = st.session_state.batch_progress

    st.markdown("### ğŸš€ ãƒãƒƒãƒæœ€é©åŒ–å®Ÿè¡Œä¸­")

    # å…¨ä½“é€²æ—
    total = progress.get("total", 1)
    current = progress.get("current", 0)
    pct = current / max(total, 1)

    st.progress(pct, text=f"å…¨ä½“é€²æ—: {current}/{total} ({pct:.0%})")

    # ç¾åœ¨ã®å‡¦ç†
    status = progress.get("status", "")
    if status:
        st.markdown(f"**ç¾åœ¨å‡¦ç†ä¸­:** {status}")

    # è©³ç´°é€²æ—
    grid_current = progress.get("grid_current", 0)
    grid_total = progress.get("grid_total", 0)
    search_method = st.session_state.get("batch_search_method", "grid")
    search_label = "ğŸ§¬ GA" if search_method == "ga" else "ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ"
    if grid_total > 0:
        grid_pct = grid_current / grid_total
        st.progress(grid_pct, text=f"{search_label}: {grid_current:,}/{grid_total:,}")

    # çµ±è¨ˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("âœ… å®Œäº†", progress.get("completed", 0))
    with col2:
        st.metric("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—", progress.get("skipped", 0))
    with col3:
        st.metric("âŒ ã‚¨ãƒ©ãƒ¼", progress.get("errors", 0))

    # ä¸­æ­¢ãƒœã‚¿ãƒ³
    if st.button("â¹ï¸ ä¸­æ­¢", type="secondary"):
        st.session_state.batch_running = False
        st.session_state.batch_cancel_requested = True
        st.rerun()


def _start_batch_optimization(scan_result: Dict[str, Any]):
    """ãƒãƒƒãƒæœ€é©åŒ–ã‚’é–‹å§‹"""
    from optimizer.adaptive import (
        AdaptiveSearchConfig, ScoutConfig, PlateauConfig, RoundConfig,
    )

    selected_symbols = st.session_state.get("batch_selected_symbols", [])
    selected_periods = st.session_state.get("batch_selected_periods", [])
    tf_combos = st.session_state.get("batch_tf_combos", [])
    selected_templates = st.session_state.get("batch_selected_templates", [])
    selected_exit_profiles = st.session_state.get("batch_selected_exit_profiles", [])
    selected_regimes = st.session_state.get("batch_selected_regimes", TARGET_REGIMES)
    use_oos = st.session_state.get("batch_use_oos", True)
    use_blacklist = st.session_state.get("batch_use_blacklist", True)
    n_workers = st.session_state.get("batch_n_workers", 4)
    reuse_existing = st.session_state.get("batch_reuse_existing", True)

    # æ¢ç´¢æ–¹æ³•ã‚’å–å¾—
    search_method = st.session_state.get("batch_search_method", "grid")

    # GAè¨­å®š
    ga_config = None
    if search_method == "ga":
        ga_config = GAConfig(
            population_size=st.session_state.get("batch_ga_population", 20),
            max_generations=st.session_state.get("batch_ga_generations", 10),
            elite_ratio=st.session_state.get("batch_ga_elite", 0.25),
            mutation_rate=st.session_state.get("batch_ga_mutation", 0.15),
            convergence_threshold=0.01,
            convergence_generations=4,
        )

    # é©å¿œå‹æ¢ç´¢ã®è¨­å®šã‚’å–å¾—ï¼ˆã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®å ´åˆã®ã¿ï¼‰
    adaptive_config = None
    enable_adaptive = st.session_state.get("batch_enable_adaptive", False) if search_method == "grid" else False

    if enable_adaptive:
        adaptive_config = AdaptiveSearchConfig(
            scout=ScoutConfig(
                sample_ratio=st.session_state.get("batch_scout_ratio", 0.2),
                top_n_to_scale=st.session_state.get("batch_scout_top_n", 20),
            ),
            plateau=PlateauConfig(
                min_improvement=st.session_state.get("batch_plateau_threshold", 0.001),
                consecutive_rounds=st.session_state.get("batch_plateau_rounds", 2),
            ),
            round=RoundConfig(
                max_rounds=st.session_state.get("batch_max_rounds", 5),
                top_n_survivors=st.session_state.get("batch_top_n_survivors", 10),
                exploration_ratio=st.session_state.get("batch_exploration_ratio", 0.2),
            ),
            enable_scout=True,
            enable_plateau=True,
            enable_rounds=True,
            verbose=True,
        )

    files = scan_result["files"]

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not selected_symbols:
        st.error("éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„")
        return
    if not tf_combos:
        st.error("æœ‰åŠ¹ãªTFã‚³ãƒ³ãƒœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    if not selected_templates:
        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
        return
    if not selected_regimes:
        st.error("ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„")
        return

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = RESULTS_DIR / timestamp
    output_dir.mkdir(parents=True, exist_ok=True)

    # ã‚¸ãƒ§ãƒ–ãƒªã‚¹ãƒˆä½œæˆ
    jobs = []
    for symbol in selected_symbols:
        for period in selected_periods:
            for exec_tf, htf in tf_combos:
                if (symbol, exec_tf, period) in files and (symbol, htf, period) in files:
                    jobs.append({
                        "symbol": symbol,
                        "period": period,
                        "exec_tf": exec_tf,
                        "htf": htf,
                    })

    # é€²æ—åˆæœŸåŒ–
    st.session_state.batch_running = True
    st.session_state.batch_cancel_requested = False
    st.session_state.batch_progress = {
        "current": 0,
        "total": len(jobs),
        "completed": 0,
        "skipped": 0,
        "errors": 0,
        "status": "",
        "grid_current": 0,
        "grid_total": 0,
    }
    st.session_state.batch_output_dir = str(output_dir)

    # configç”Ÿæˆ
    all_configs = generate_all_configs(selected_templates, selected_exit_profiles)

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    progress_placeholder = st.empty()
    grid_progress_placeholder = st.empty()
    status_placeholder = st.empty()
    stats_placeholder = st.empty()
    cancel_placeholder = st.empty()

    # é€²æ—ãƒ©ãƒ™ãƒ«ï¼ˆæ¢ç´¢æ–¹æ³•ã«ã‚ˆã£ã¦å¤‰æ›´ï¼‰
    search_label = "ğŸ§¬ GA" if search_method == "ga" else "ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ"

    # åˆæœŸçŠ¶æ…‹ã‚’è¡¨ç¤º
    with progress_placeholder.container():
        st.progress(0.0, text=f"å…¨ä½“é€²æ—: 0/{len(jobs)} (0%)")
    with grid_progress_placeholder.container():
        st.progress(0.0, text=f"{search_label}: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    with status_placeholder.container():
        st.markdown(f"**ğŸš€ ãƒãƒƒãƒæœ€é©åŒ–é–‹å§‹** - {len(jobs)}ä»¶ã®ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã—ã¾ã™ ({search_label})")
    with stats_placeholder.container():
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("âœ… å®Œäº†", 0)
        with col2:
            st.metric("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—", 0)
        with col3:
            st.metric("âŒ ã‚¨ãƒ©ãƒ¼", 0)
    with cancel_placeholder.container():
        if st.button("â¹ï¸ ä¸­æ­¢", type="secondary", key="batch_cancel_btn"):
            st.session_state.batch_running = False
            st.session_state.batch_cancel_requested = True
            st.rerun()

    def update_progress(completed: int, total: int, desc: str):
        """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        st.session_state.batch_progress["grid_current"] = completed
        st.session_state.batch_progress["grid_total"] = total
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ›´æ–°
        if total > 0:
            grid_pct = completed / total
            grid_progress_placeholder.progress(grid_pct, text=f"{search_label}: {completed:,}/{total:,}")

    # å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
    for i, job in enumerate(jobs):
        if st.session_state.get("batch_cancel_requested", False):
            break

        symbol = job["symbol"]
        period = job["period"]
        exec_tf = job["exec_tf"]
        htf = job["htf"]

        st.session_state.batch_progress["current"] = i + 1
        st.session_state.batch_progress["status"] = f"{symbol} | {exec_tf}/{htf} | {period}"
        st.session_state.batch_progress["grid_current"] = 0
        st.session_state.batch_progress["grid_total"] = 0

        # æ—¢å­˜çµæœãƒã‚§ãƒƒã‚¯
        existing_file = output_dir / f"{symbol}_{period}_{exec_tf}_{htf}.json"
        if reuse_existing and existing_file.exists():
            st.session_state.batch_progress["skipped"] += 1
            continue

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
            tf_dict = load_symbol_data(symbol, period, exec_tf, htf, files)

            # Dual-TF EMAç”¨ã®super_htfãƒ‡ãƒ¼ã‚¿
            _trend_method = st.session_state.get("batch_trend_method", "ma_cross")
            _super_htf = st.session_state.get("batch_super_htf")
            _super_htf_df = None
            if _trend_method == "dual_tf_ema" and _super_htf:
                super_htf_path = files.get((symbol, _super_htf, period))
                if super_htf_path:
                    loader = BinanceCSVLoader()
                    _super_htf_df = loader.load(str(super_htf_path), symbol=symbol).df.copy()

            exec_df = prepare_exec_df(
                tf_dict, exec_tf, htf,
                trend_method=_trend_method,
                super_htf_df=_super_htf_df,
            )

            if search_method == "ga":
                # GAæœ€é©åŒ–å®Ÿè¡Œï¼ˆOOSæ¤œè¨¼ä»˜ãï¼‰
                ga_results = run_single_ga_optimization(
                    exec_df=exec_df,
                    templates=selected_templates,
                    target_regimes=selected_regimes,
                    ga_config=ga_config,
                    symbol=symbol,
                    progress_callback=update_progress,
                    use_oos=use_oos,
                    use_blacklist=use_blacklist,
                )

                # GAçµæœä¿å­˜
                for ga_result in ga_results:
                    ga_result.save(str(output_dir))

                # GAé€²æ—ã‚’å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
                total_gens = len(selected_regimes) * ga_config.max_generations
                st.session_state.batch_progress["grid_current"] = total_gens
                st.session_state.batch_progress["grid_total"] = total_gens
                grid_progress_placeholder.progress(1.0, text=f"{search_label}: å®Œäº†")

                result = None  # GAã¯åˆ¥å½¢å¼ã§ä¿å­˜

            else:
                # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒæœ€é©åŒ–å®Ÿè¡Œ
                result = run_single_optimization(
                    exec_df=exec_df,
                    all_configs=all_configs,
                    use_oos=use_oos,
                    n_workers=n_workers,
                    target_regimes=selected_regimes,
                    progress_callback=update_progress,
                    adaptive_config=adaptive_config,
                )

                # çµæœä¿å­˜
                save_batch_result(
                    result=result,
                    symbol=symbol,
                    period=period,
                    exec_tf=exec_tf,
                    htf=htf,
                    use_oos=use_oos,
                    output_dir=output_dir,
                )

            st.session_state.batch_progress["completed"] += 1

        except Exception as e:
            st.session_state.batch_progress["errors"] += 1
            st.error(f"ã‚¨ãƒ©ãƒ¼: {symbol} | {exec_tf}/{htf} | {period}: {e}")

        # UIæ›´æ–°ï¼ˆé€²æ—è¡¨ç¤ºï¼‰
        with progress_placeholder.container():
            progress = st.session_state.batch_progress
            pct = progress["current"] / max(progress["total"], 1)
            st.progress(pct, text=f"å…¨ä½“é€²æ—: {progress['current']}/{progress['total']} ({pct:.0%})")

        with grid_progress_placeholder.container():
            grid_current = st.session_state.batch_progress.get("grid_current", 0)
            grid_total = st.session_state.batch_progress.get("grid_total", 0)
            if grid_total > 0:
                grid_pct = grid_current / grid_total
                st.progress(grid_pct, text=f"{search_label}: {grid_current:,}/{grid_total:,}")
            else:
                st.progress(0.0, text=f"{search_label}: æº–å‚™ä¸­...")

        with status_placeholder.container():
            st.markdown(f"**ç¾åœ¨å‡¦ç†ä¸­:** {st.session_state.batch_progress['status']}")

        with stats_placeholder.container():
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("âœ… å®Œäº†", st.session_state.batch_progress["completed"])
            with col2:
                st.metric("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—", st.session_state.batch_progress["skipped"])
            with col3:
                st.metric("âŒ ã‚¨ãƒ©ãƒ¼", st.session_state.batch_progress["errors"])

    # å®Œäº†
    st.session_state.batch_running = False

    progress = st.session_state.batch_progress
    st.success(
        f"ğŸ‰ ãƒãƒƒãƒæœ€é©åŒ–å®Œäº†ï¼\n\n"
        f"- å®Œäº†: {progress['completed']} ä»¶\n"
        f"- ã‚¹ã‚­ãƒƒãƒ—: {progress['skipped']} ä»¶\n"
        f"- ã‚¨ãƒ©ãƒ¼: {progress['errors']} ä»¶\n\n"
        f"çµæœ: `{output_dir}`"
    )


# =============================================================================
# ãƒãƒƒãƒçµæœèª­ã¿è¾¼ã¿ãƒ»è¡¨ç¤º
# =============================================================================

def list_batch_result_dirs() -> List[Dict[str, Any]]:
    """results/batchãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒçµæœä¸€è¦§ã‚’å–å¾—"""
    result_dirs = []

    if not RESULTS_DIR.exists():
        return result_dirs

    for d in sorted(RESULTS_DIR.iterdir(), reverse=True):
        if not d.is_dir():
            continue

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåãŒã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ã‹ç¢ºèª
        if not re.match(r"^\d{8}_\d{6}$", d.name):
            continue

        # JSONæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        json_files = list(d.glob("*.json"))
        if not json_files:
            continue

        # GAçµæœã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆga_ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ï¼‰
        ga_files = [f for f in json_files if f.name.startswith("ga_")]
        is_ga = len(ga_files) > 0

        # æœ€åˆã®JSONã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        try:
            with open(json_files[0], "r", encoding="utf-8") as f:
                sample = json.load(f)
        except Exception:
            continue

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ä¸€è¦§ã‚’æŠ½å‡º
        symbols = set()
        for jf in json_files:
            if jf.name.startswith("ga_"):
                # GAå½¢å¼: ga_BTCUSDT_uptrend_20260205_180454.json
                parts = jf.stem.split("_")
                if len(parts) >= 2:
                    symbols.add(parts[1])
            else:
                # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå½¢å¼: BTCUSDT_20250201-20260130_15m_1h.json
                parts = jf.stem.split("_")
                if parts:
                    symbols.add(parts[0])

        # æ—¥æ™‚ã‚’ãƒ‘ãƒ¼ã‚¹
        dt_str = d.name  # 20260204_174904
        dt_display = f"{dt_str[:4]}/{dt_str[4:6]}/{dt_str[6:8]} {dt_str[9:11]}:{dt_str[11:13]}"

        result_dirs.append({
            "path": d,
            "name": d.name,
            "datetime": dt_display,
            "file_count": len(json_files),
            "symbols": sorted(symbols),
            "oos": sample.get("oos", False),
            "is_ga": is_ga,  # GAçµæœã‹ã©ã†ã‹
        })

    return result_dirs


def load_batch_result_files(dir_path: Path) -> List[Dict[str, Any]]:
    """æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å…¨JSONã‚’èª­ã¿è¾¼ã¿"""
    results = []

    for jf in sorted(dir_path.glob("*.json")):
        try:
            with open(jf, "r", encoding="utf-8") as f:
                data = json.load(f)
            data["_file"] = jf.name
            results.append(data)
        except Exception:
            continue

    return results


def _render_blacklist_management():
    """ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆç®¡ç†UI"""
    st.markdown("### ğŸš« ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆç®¡ç†")
    st.caption("OOSæ¤œè¨¼ã§FAILã—ãŸçµ„ã¿åˆã‚ã›ï¼ˆéŠ˜æŸ„ Ã— ãƒ¬ã‚¸ãƒ¼ãƒ  Ã— ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰ã‚’ç®¡ç†")

    blacklist = get_blacklist()

    if not blacklist.entries:
        st.info("ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã¯ç©ºã§ã™ã€‚OOSæ¤œè¨¼ã§FAILã™ã‚‹ã¨è‡ªå‹•çš„ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
        return

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = blacklist.summary()
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("åˆè¨ˆ", summary["total"])
    with col2:
        regime_str = ", ".join(f"{k}: {v}" for k, v in summary["by_regime"].items())
        st.metric("ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥", regime_str or "â€”")
    with col3:
        top_templates = sorted(summary["by_template"].items(), key=lambda x: -x[1])[:3]
        template_str = ", ".join(f"{k}: {v}" for k, v in top_templates)
        st.metric("Top3ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", template_str or "â€”")

    # ä¸€è¦§è¡¨ç¤º
    st.markdown("---")
    df_blacklist = pd.DataFrame([
        {
            "éŠ˜æŸ„": e.symbol,
            "ãƒ¬ã‚¸ãƒ¼ãƒ ": e.regime,
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ": e.template,
            "Test PnL": f"{e.test_pnl:.2f}%" if e.test_pnl is not None else "â€”",
            "Train PnL": f"{e.train_pnl:.2f}%" if e.train_pnl is not None else "â€”",
            "è¿½åŠ æ—¥": e.added_at,
            "ç†ç”±": e.reason,
        }
        for e in blacklist.entries
    ])

    # ãƒ•ã‚£ãƒ«ã‚¿
    col1, col2, col3 = st.columns(3)
    with col1:
        filter_regime = st.selectbox(
            "ãƒ¬ã‚¸ãƒ¼ãƒ ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=["ã™ã¹ã¦"] + list(set(e.regime for e in blacklist.entries)),
            key="blacklist_filter_regime",
        )
    with col2:
        filter_symbol = st.selectbox(
            "éŠ˜æŸ„ã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=["ã™ã¹ã¦"] + sorted(set(e.symbol for e in blacklist.entries)),
            key="blacklist_filter_symbol",
        )
    with col3:
        filter_template = st.selectbox(
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ãƒ•ã‚£ãƒ«ã‚¿",
            options=["ã™ã¹ã¦"] + sorted(set(e.template for e in blacklist.entries)),
            key="blacklist_filter_template",
        )

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    df_filtered = df_blacklist.copy()
    if filter_regime != "ã™ã¹ã¦":
        df_filtered = df_filtered[df_filtered["ãƒ¬ã‚¸ãƒ¼ãƒ "] == filter_regime]
    if filter_symbol != "ã™ã¹ã¦":
        df_filtered = df_filtered[df_filtered["éŠ˜æŸ„"] == filter_symbol]
    if filter_template != "ã™ã¹ã¦":
        df_filtered = df_filtered[df_filtered["ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"] == filter_template]

    st.dataframe(df_filtered, use_container_width=True, hide_index=True)

    # å‰Šé™¤æ©Ÿèƒ½
    st.markdown("---")
    st.markdown("#### âš ï¸ ã‚¨ãƒ³ãƒˆãƒªå‰Šé™¤")
    col1, col2 = st.columns([3, 1])
    with col1:
        delete_options = [
            f"{e.symbol} / {e.regime} / {e.template}"
            for e in blacklist.entries
        ]
        selected_delete = st.multiselect(
            "å‰Šé™¤ã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’é¸æŠ",
            options=delete_options,
            key="blacklist_delete_select",
        )
    with col2:
        if st.button("ğŸ—‘ï¸ é¸æŠã‚’å‰Šé™¤", type="secondary", disabled=not selected_delete):
            for item in selected_delete:
                parts = item.split(" / ")
                if len(parts) == 3:
                    blacklist.remove(parts[0], parts[1], parts[2])
            blacklist.save()
            st.success(f"{len(selected_delete)}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            st.rerun()

    # å…¨å‰Šé™¤
    with st.expander("âš ï¸ å…¨å‰Šé™¤ï¼ˆæ³¨æ„ï¼‰"):
        if st.button("ğŸ—‘ï¸ ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’å…¨å‰Šé™¤", type="secondary"):
            count = blacklist.clear()
            blacklist.save()
            st.success(f"{count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            st.rerun()


def render_batch_load_view():
    """ãƒãƒƒãƒçµæœèª­ã¿è¾¼ã¿ãƒ»è¡¨ç¤ºãƒ“ãƒ¥ãƒ¼ã‚’æç”»"""
    st.subheader("ğŸ“ ãƒãƒƒãƒçµæœèª­ã¿è¾¼ã¿")

    # ã‚µãƒ–ãƒ“ãƒ¥ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
    sub_view = st.radio(
        "è¡¨ç¤º",
        options=["ğŸ“‚ çµæœä¸€è¦§", "ğŸš« ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ"],
        horizontal=True,
        key="batch_load_sub_view",
    )

    st.markdown("---")

    if sub_view == "ğŸš« ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ":
        _render_blacklist_management()
        return

    # --- çµæœä¸€è¦§ãƒ“ãƒ¥ãƒ¼ ---
    st.caption("ä¿å­˜ã•ã‚ŒãŸãƒãƒƒãƒæœ€é©åŒ–çµæœã‚’é–²è¦§")

    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—
    result_dirs = list_batch_result_dirs()

    if not result_dirs:
        st.info(
            "ğŸ“‚ ãƒãƒƒãƒçµæœãŒã‚ã‚Šã¾ã›ã‚“\n\n"
            f"ãƒ‘ã‚¹: `{RESULTS_DIR}`\n\n"
            "ã€ŒğŸš€ ãƒãƒƒãƒã€ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        )
        return

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    if "batch_load_selected" not in st.session_state:
        st.session_state.batch_load_selected = None
    if "batch_load_data" not in st.session_state:
        st.session_state.batch_load_data = None

    # --- çµæœä¸€è¦§ ---
    st.markdown("### ä¿å­˜æ¸ˆã¿ãƒãƒƒãƒçµæœ")

    # ä¸€è¦§ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡¨ç¤º
    df_dirs = pd.DataFrame([
        {
            "é¸æŠ": False,
            "æ—¥æ™‚": d["datetime"],
            "ä»¶æ•°": d["file_count"],
            "éŠ˜æŸ„": ", ".join(d["symbols"][:5]) + ("..." if len(d["symbols"]) > 5 else ""),
            "OOS": "âœ…" if d["oos"] else "â€”",
            "ãƒ‘ã‚¹": d["name"],
        }
        for d in result_dirs
    ])

    # é¸æŠ
    col1, col2 = st.columns([3, 1])
    with col1:
        selected_name = st.selectbox(
            "çµæœã‚’é¸æŠ",
            options=[d["name"] for d in result_dirs],
            format_func=lambda x: next(
                f"{d['datetime']} | {d['file_count']}ä»¶ | {'ga' if d.get('is_ga') else 'grid'}"
                for d in result_dirs if d["name"] == x
            ),
            key="batch_load_selector",
        )
    with col2:
        if st.button("ğŸ“‚ èª­ã¿è¾¼ã¿", type="primary", use_container_width=True):
            selected_dir = next(d for d in result_dirs if d["name"] == selected_name)
            st.session_state.batch_load_selected = selected_dir
            st.session_state.batch_load_data = load_batch_result_files(selected_dir["path"])
            st.rerun()

    # --- èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º ---
    if st.session_state.batch_load_data:
        selected = st.session_state.batch_load_selected
        if selected.get("is_ga"):
            _render_ga_results_detail()
        else:
            _render_batch_results_detail()


def _render_ga_results_detail():
    """GAçµæœã®è©³ç´°ã‚’è¡¨ç¤º"""
    data_list = st.session_state.batch_load_data
    selected = st.session_state.batch_load_selected

    st.divider()
    st.markdown(f"### ğŸ§¬ GAçµæœ: {selected['datetime']}")
    st.caption(f"{len(data_list)}ä»¶ã®GAçµæœ")

    # GAçµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´å½¢
    table_data = []
    has_oos = False  # OOSæ¤œè¨¼çµæœãŒã‚ã‚‹ã‹ã©ã†ã‹

    for data in data_list:
        if "final_winner" not in data:
            continue  # GAçµæœã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        winner = data.get("final_winner", {})

        # OOSæ¤œè¨¼çµæœã®æœ‰ç„¡ã‚’ç¢ºèª
        has_verdict = "verdict" in winner
        if has_verdict:
            has_oos = True

        row = {
            "éŠ˜æŸ„": data.get("symbol", "?"),
            "ãƒ¬ã‚¸ãƒ¼ãƒ ": data.get("regime", "?"),
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ": winner.get("template", "?"),
        }

        trades = winner.get("trades", 0)

        # OOSæ¤œè¨¼çµæœãŒã‚ã‚‹å ´åˆ
        if has_verdict:
            verdict = winner.get("verdict", "?")
            train_pnl = winner.get("train_pnl", 0)
            test_pnl = winner.get("test_pnl", 0)

            # å®‰å®šåº¦ (Test/Trainæ¯”ç‡)
            if train_pnl > 0:
                stability = test_pnl / train_pnl
            elif train_pnl < 0 and test_pnl > 0:
                stability = 2.0  # Trainè² ã‘â†’Testå‹ã¡ã¯é«˜è©•ä¾¡
            else:
                stability = 0.0

            # æ¡ç”¨ã‚¹ã‚³ã‚¢è¨ˆç®—
            # Test PnL Ã— 0.4 + å®‰å®šåº¦ Ã— 0.3 + ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°æ­£è¦åŒ– Ã— 0.3
            test_pnl_score = max(0, min(test_pnl / 30, 1.0))  # 30%ã§æº€ç‚¹
            stability_score = max(0, min(stability, 1.0))  # 1.0ã§æº€ç‚¹
            trades_score = min(trades / 100, 1.0)  # 100å›ã§æº€ç‚¹
            adoption_score = test_pnl_score * 0.4 + stability_score * 0.3 + trades_score * 0.3

            row["Test PnL"] = f"{test_pnl:+.2f}%"
            row["å®‰å®šåº¦"] = f"{stability:.2f}"
            row["ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°"] = trades
            row["æ¡ç”¨ã‚¹ã‚³ã‚¢"] = round(adoption_score, 2)
            row["æ¡ç”¨"] = "â­" if verdict == "PASS" and adoption_score >= 0.5 else "â€”"
            row["åˆ¤å®š"] = verdict
            row["_test_pnl"] = test_pnl  # ã‚½ãƒ¼ãƒˆç”¨ï¼ˆéè¡¨ç¤ºï¼‰
            row["_adoption_score"] = adoption_score  # ã‚½ãƒ¼ãƒˆç”¨ï¼ˆéè¡¨ç¤ºï¼‰
        else:
            row["PnL (%)"] = f"{winner.get('pnl', 0):+.2f}%"
            row["ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°"] = trades
            row["_test_pnl"] = winner.get("pnl", 0)
            row["_adoption_score"] = 0

        table_data.append(row)

    if not table_data:
        st.warning("è©²å½“ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    df = pd.DataFrame(table_data)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        symbols = ["ã™ã¹ã¦"] + sorted(df["éŠ˜æŸ„"].unique().tolist())
        filter_symbol = st.selectbox("éŠ˜æŸ„", options=symbols, key="ga_filter_symbol")
    with col2:
        regimes = ["ã™ã¹ã¦"] + sorted(df["ãƒ¬ã‚¸ãƒ¼ãƒ "].unique().tolist())
        filter_regime = st.selectbox("ãƒ¬ã‚¸ãƒ¼ãƒ ", options=regimes, key="ga_filter_regime")
    with col3:
        # åˆ¤å®šãƒ•ã‚£ãƒ«ã‚¿ï¼ˆOOSçµæœãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if has_oos:
            verdict_options = ["ã™ã¹ã¦", "PASSã®ã¿", "FAILã®ã¿"]
            filter_verdict = st.selectbox("åˆ¤å®š", options=verdict_options, key="ga_filter_verdict")
        else:
            filter_verdict = "ã™ã¹ã¦"
    with col4:
        min_trades = st.number_input(
            "æœ€å°ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°",
            min_value=0,
            max_value=100,
            value=0,
            step=5,
            key="ga_filter_min_trades",
        )

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    filtered = df.copy()
    if filter_symbol != "ã™ã¹ã¦":
        filtered = filtered[filtered["éŠ˜æŸ„"] == filter_symbol]
    if filter_regime != "ã™ã¹ã¦":
        filtered = filtered[filtered["ãƒ¬ã‚¸ãƒ¼ãƒ "] == filter_regime]
    if has_oos and filter_verdict == "PASSã®ã¿":
        filtered = filtered[filtered["åˆ¤å®š"] == "PASS"]
    elif has_oos and filter_verdict == "FAILã®ã¿":
        filtered = filtered[filtered["åˆ¤å®š"] == "FAIL"]
    if min_trades > 0:
        filtered = filtered[filtered["ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°"] >= min_trades]

    # æ¡ç”¨ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆï¼ˆOOSçµæœãŒã‚ã‚‹å ´åˆï¼‰
    if has_oos and "_adoption_score" in filtered.columns:
        filtered = filtered.sort_values("_adoption_score", ascending=False)

    # éè¡¨ç¤ºåˆ—ã‚’é™¤å¤–
    display_cols = [c for c in filtered.columns if not c.startswith("_")]
    display_df = filtered[display_cols]

    # ä»¶æ•°è¡¨ç¤º
    st.caption(f"è¡¨ç¤º: {len(display_df)}ä»¶ / å…¨{len(df)}ä»¶")
    st.dataframe(display_df, use_container_width=True, hide_index=True)

    # ä¸–ä»£æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆ
    with st.expander("ğŸ“ˆ ä¸–ä»£ã”ã¨ã®ã‚¹ã‚³ã‚¢æ¨ç§»", expanded=False):
        for data in data_list:
            if "generations" not in data:
                continue
            symbol = data.get("symbol", "?")
            regime = data.get("regime", "?")
            if filter_symbol != "ã™ã¹ã¦" and symbol != filter_symbol:
                continue
            if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                continue

            st.caption(f"**{symbol} - {regime}**")
            gen_data = []
            for gen in data.get("generations", []):
                gen_data.append({
                    "ä¸–ä»£": gen.get("generation", 0),
                    "ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢": gen.get("best_score", 0),
                    "å¹³å‡ã‚¹ã‚³ã‚¢": gen.get("avg_score", 0),
                })
            if gen_data:
                chart_df = pd.DataFrame(gen_data)
                st.line_chart(chart_df.set_index("ä¸–ä»£"))

    # æ¡ç”¨å€™è£œã‚’ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒãƒœã‚¿ãƒ³
    if has_oos:
        st.divider()
        st.markdown("### ğŸ”¬ æ¡ç”¨å€™è£œã‚’ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ")

        # æ¡ç”¨å€™è£œã‚’æŠ½å‡ºï¼ˆâ­ã®ã‚‚ã®ï¼‰
        adopted_rows = filtered[filtered["æ¡ç”¨"] == "â­"] if "æ¡ç”¨" in filtered.columns else pd.DataFrame()
        n_adopted = len(adopted_rows)

        if n_adopted == 0:
            st.info("æ¡ç”¨å€™è£œï¼ˆâ­ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        else:
            # æ¡ç”¨å€™è£œã®éŠ˜æŸ„ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æŠ½å‡º
            adopted_symbols = adopted_rows["éŠ˜æŸ„"].unique().tolist()
            adopted_templates = adopted_rows["ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"].unique().tolist()

            st.caption(f"æ¡ç”¨å€™è£œ: {n_adopted}ä»¶ | éŠ˜æŸ„: {len(adopted_symbols)}ç¨® | ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(adopted_templates)}ç¨®")

            col1, col2 = st.columns([2, 1])
            with col1:
                st.markdown(f"**éŠ˜æŸ„:** {', '.join(adopted_symbols[:10])}{'...' if len(adopted_symbols) > 10 else ''}")
                st.markdown(f"**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:** {', '.join(adopted_templates[:5])}{'...' if len(adopted_templates) > 5 else ''}")

            with col2:
                if st.button("ğŸš€ ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒé–‹å§‹", type="primary", use_container_width=True):
                    # æ¡ç”¨å€™è£œãƒªã‚¹ãƒˆã‚’session_stateã«ä¿å­˜
                    st.session_state.ga_adopted_candidates = {
                        "symbols": adopted_symbols,
                        "templates": adopted_templates,
                        "source": selected["datetime"],
                    }
                    # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒãƒ¢ãƒ¼ãƒ‰ã‚’ã‚»ãƒƒãƒˆ
                    st.session_state.batch_search_method = "grid"
                    st.session_state.batch_from_ga_candidates = True
                    # è‡ªå‹•å®Ÿè¡Œãƒ•ãƒ©ã‚°
                    st.session_state.batch_auto_start = True

                    # æ—¢å­˜ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢ï¼ˆGAå€™è£œã®defaultå€¤ã‚’æœ‰åŠ¹ã«ã™ã‚‹ãŸã‚ï¼‰
                    keys_to_delete = [k for k in st.session_state.keys()
                                      if k.startswith("batch_symbol_") or k.startswith("batch_template_")]
                    for k in keys_to_delete:
                        del st.session_state[k]

                    # ãƒãƒƒãƒã‚¿ãƒ–ã«è‡ªå‹•é·ç§»
                    st.session_state.optimizer_view = "batch"
                    st.rerun()


def _render_batch_results_detail():
    """èª­ã¿è¾¼ã‚“ã ãƒãƒƒãƒçµæœã®è©³ç´°ã‚’è¡¨ç¤º"""
    data_list = st.session_state.batch_load_data
    selected = st.session_state.batch_load_selected

    st.divider()
    st.markdown(f"### ğŸ“Š çµæœè©³ç´°: {selected['datetime']}")
    st.caption(f"{len(data_list)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ | OOS: {'æœ‰åŠ¹' if selected['oos'] else 'ç„¡åŠ¹'}")

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    col1, col2, col3 = st.columns(3)

    # éŠ˜æŸ„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    all_symbols = sorted(set(d["symbol"] for d in data_list))
    with col1:
        filter_symbol = st.selectbox(
            "éŠ˜æŸ„",
            options=["ã™ã¹ã¦"] + all_symbols,
            key="batch_result_filter_symbol",
        )

    # ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    with col2:
        filter_regime = st.selectbox(
            "ãƒ¬ã‚¸ãƒ¼ãƒ ",
            options=["ã™ã¹ã¦", "uptrend", "downtrend", "range"],
            key="batch_result_filter_regime",
        )

    # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    with col3:
        view_mode = st.radio(
            "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
            options=["ã‚µãƒãƒªãƒ¼", "è©³ç´°"],
            horizontal=True,
            key="batch_result_view_mode",
        )

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    filtered_data = data_list
    if filter_symbol != "ã™ã¹ã¦":
        filtered_data = [d for d in filtered_data if d["symbol"] == filter_symbol]

    if view_mode == "ã‚µãƒãƒªãƒ¼":
        _render_batch_summary_view(filtered_data, filter_regime)
    else:
        _render_batch_detail_view(filtered_data, filter_regime)


def _render_batch_summary_view(data_list: List[Dict], filter_regime: str):
    """ã‚µãƒãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼: ãƒ¬ã‚¸ãƒ¼ãƒ Ã—éŠ˜æŸ„ã”ã¨ã®ãƒ™ã‚¹ãƒˆæˆ¦ç•¥"""

    # å„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ã‚¸ãƒ¼ãƒ ã”ã¨ã®ãƒ™ã‚¹ãƒˆã‚’æŠ½å‡º
    summary_rows = []

    for data in data_list:
        symbol = data["symbol"]
        period = data.get("period", "")
        exec_tf = data.get("execution_tf", "")
        htf = data.get("htf", "")
        is_oos = data.get("oos", False)

        if is_oos and "test_results" in data:
            # OOSçµæœï¼ˆtest_resultsï¼‰ã‚’ä½¿ç”¨
            test_results = data["test_results"]
            for regime, entry in test_results.items():
                if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                    continue

                pnl = entry.get("metrics", {}).get("total_pnl", 0)
                trades = entry.get("metrics", {}).get("trades", 0)

                # æ¡ç”¨ã‚¹ã‚³ã‚¢è¨ˆç®—
                pnl_score = max(0, min(pnl / 30, 1.0))  # 30%ã§æº€ç‚¹
                trades_score = min(trades / 100, 1.0)  # 100å›ã§æº€ç‚¹
                adoption_score = pnl_score * 0.5 + trades_score * 0.5

                # æ¡ç”¨åˆ¤å®š: PnL > 0 ã‹ã¤ å–å¼•æ•° >= 30 ã‹ã¤ æ¡ç”¨ã‚¹ã‚³ã‚¢ >= 0.3
                is_adopted = pnl > 0 and trades >= 30 and adoption_score >= 0.3

                summary_rows.append({
                    "éŠ˜æŸ„": symbol,
                    "æœŸé–“": period,
                    "TF": f"{exec_tf}/{htf}",
                    "ãƒ¬ã‚¸ãƒ¼ãƒ ": _regime_label(regime),
                    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ": _template_label(entry.get("template", "")),
                    "Exit": entry.get("exit_profile", ""),
                    "ã‚¹ã‚³ã‚¢": entry.get("score", 0),
                    "å‹ç‡": entry.get("metrics", {}).get("win_rate", 0),
                    "PF": entry.get("metrics", {}).get("profit_factor", 0),
                    "PnL%": pnl,
                    "DD%": entry.get("metrics", {}).get("max_dd", 0),
                    "å–å¼•æ•°": trades,
                    "æ¡ç”¨ã‚¹ã‚³ã‚¢": round(adoption_score, 2),
                    "æ¡ç”¨": "â­" if is_adopted else "â€”",
                })
        elif "results" in data:
            # é€šå¸¸çµæœ
            for entry in data["results"][:3]:  # ä¸Šä½3ä»¶
                regime = entry.get("regime", "all")
                if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                    continue

                pnl = entry.get("metrics", {}).get("total_pnl", 0)
                trades = entry.get("metrics", {}).get("trades", 0)

                # æ¡ç”¨ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆOOSãªã—ã®å ´åˆã¯å‚è€ƒå€¤ï¼‰
                pnl_score = max(0, min(pnl / 30, 1.0))
                trades_score = min(trades / 100, 1.0)
                adoption_score = pnl_score * 0.5 + trades_score * 0.5

                summary_rows.append({
                    "éŠ˜æŸ„": symbol,
                    "æœŸé–“": period,
                    "TF": f"{exec_tf}/{htf}",
                    "ãƒ¬ã‚¸ãƒ¼ãƒ ": _regime_label(regime),
                    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ": _template_label(entry.get("template", "")),
                    "Exit": entry.get("exit_profile", ""),
                    "ã‚¹ã‚³ã‚¢": entry.get("score", 0),
                    "å‹ç‡": entry.get("metrics", {}).get("win_rate", 0),
                    "PF": entry.get("metrics", {}).get("profit_factor", 0),
                    "PnL%": pnl,
                    "DD%": entry.get("metrics", {}).get("max_dd", 0),
                    "å–å¼•æ•°": trades,
                    "æ¡ç”¨ã‚¹ã‚³ã‚¢": round(adoption_score, 2),
                    "æ¡ç”¨": "â€”",  # OOSãªã—ã¯æ¡ç”¨åˆ¤å®šã—ãªã„
                })

    if not summary_rows:
        st.info("è©²å½“ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    df = pd.DataFrame(summary_rows)

    # æ¡ç”¨ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
    df = df.sort_values("æ¡ç”¨ã‚¹ã‚³ã‚¢", ascending=False)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col_f1, col_f2 = st.columns(2)
    with col_f1:
        filter_adopted = st.checkbox("æ¡ç”¨å€™è£œã®ã¿è¡¨ç¤º", value=False, key="batch_result_filter_adopted")
    with col_f2:
        min_trades = st.number_input("æœ€å°å–å¼•æ•°", min_value=0, value=0, step=10, key="batch_result_min_trades")

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    filtered_df = df.copy()
    if filter_adopted:
        filtered_df = filtered_df[filtered_df["æ¡ç”¨"] == "â­"]
    if min_trades > 0:
        filtered_df = filtered_df[filtered_df["å–å¼•æ•°"] >= min_trades]

    # æ¡ç”¨å€™è£œã®ä»¶æ•°ã‚’è¡¨ç¤º
    n_adopted = len(df[df["æ¡ç”¨"] == "â­"])
    st.caption(f"è¡¨ç¤º: {len(filtered_df)}ä»¶ / å…¨{len(df)}ä»¶ | æ¡ç”¨å€™è£œ: {n_adopted}ä»¶")

    st.dataframe(
        filtered_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "ã‚¹ã‚³ã‚¢": st.column_config.NumberColumn(format="%.3f"),
            "å‹ç‡": st.column_config.NumberColumn(format="%.1f%%"),
            "PF": st.column_config.NumberColumn(format="%.2f"),
            "PnL%": st.column_config.NumberColumn(format="%.2f%%"),
            "DD%": st.column_config.NumberColumn(format="%.2f%%"),
            "æ¡ç”¨ã‚¹ã‚³ã‚¢": st.column_config.NumberColumn(format="%.2f"),
        },
    )

    # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã‚µãƒãƒªãƒ¼
    st.markdown("#### ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ãƒ™ã‚¹ãƒˆæˆ¦ç•¥")

    for regime in ["uptrend", "downtrend", "range"]:
        if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
            continue

        regime_df = df[df["ãƒ¬ã‚¸ãƒ¼ãƒ "] == _regime_label(regime)]
        if regime_df.empty:
            continue

        best = regime_df.iloc[0]
        with st.expander(f"{_regime_label(regime)} - {best['éŠ˜æŸ„']} | {best['ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ']}", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ã‚¹ã‚³ã‚¢", f"{best['ã‚¹ã‚³ã‚¢']:.3f}")
            with col2:
                st.metric("å‹ç‡", f"{best['å‹ç‡']:.1f}%")
            with col3:
                st.metric("PF", f"{best['PF']:.2f}")
            with col4:
                st.metric("PnL", f"{best['PnL%']:.2f}%")

            st.markdown(f"**Exit:** `{best['Exit']}`")
            st.markdown(f"**æœŸé–“:** {best['æœŸé–“']} | **TF:** {best['TF']} | **å–å¼•æ•°:** {best['å–å¼•æ•°']}")


def _render_batch_detail_view(data_list: List[Dict], filter_regime: str):
    """è©³ç´°ãƒ“ãƒ¥ãƒ¼: å„ãƒ‡ãƒ¼ã‚¿ã®å…¨çµæœã‚’è¡¨ç¤º"""

    for data in data_list:
        symbol = data["symbol"]
        period = data.get("period", "")
        exec_tf = data.get("execution_tf", "")
        htf = data.get("htf", "")
        is_oos = data.get("oos", False)

        with st.expander(f"**{symbol}** | {exec_tf}/{htf} | {period}", expanded=False):
            if is_oos:
                # OOSçµæœ
                st.markdown("##### ğŸ† ãƒ†ã‚¹ãƒˆçµæœ (OOS)")
                if "test_results" in data:
                    for regime, entry in data["test_results"].items():
                        if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                            continue

                        st.markdown(f"**{_regime_label(regime)}**")
                        _render_entry_card(entry)

                st.markdown("##### ğŸ“ˆ è¨“ç·´ãƒ™ã‚¹ãƒˆ (Top 5)")
                if "train_results" in data:
                    for entry in data["train_results"][:5]:
                        regime = entry.get("regime", "all")
                        if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                            continue
                        _render_entry_card(entry)

                if "warnings" in data and data["warnings"]:
                    st.markdown("##### âš ï¸ ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è­¦å‘Š")
                    for w in data["warnings"]:
                        st.warning(w)
            else:
                # é€šå¸¸çµæœ
                st.markdown("##### ğŸ† Top 10")
                if "results" in data:
                    for entry in data["results"][:10]:
                        regime = entry.get("regime", "all")
                        if filter_regime != "ã™ã¹ã¦" and regime != filter_regime:
                            continue
                        _render_entry_card(entry)


def _render_entry_card(entry: Dict):
    """1ã‚¨ãƒ³ãƒˆãƒªã®ã‚«ãƒ¼ãƒ‰è¡¨ç¤º"""
    metrics = entry.get("metrics", {})
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        template = _template_label(entry.get("template", ""))
        st.markdown(f"**{template}**")
    with col2:
        st.metric("ã‚¹ã‚³ã‚¢", f"{entry.get('score', 0):.3f}")
    with col3:
        st.metric("å‹ç‡", f"{metrics.get('win_rate', 0):.1f}%")
    with col4:
        st.metric("PF", f"{metrics.get('profit_factor', 0):.2f}")
    with col5:
        st.metric("PnL", f"{metrics.get('total_pnl', 0):.2f}%")

    st.caption(f"Exit: `{entry.get('exit_profile', '')}` | å–å¼•æ•°: {metrics.get('trades', 0)} | DD: {metrics.get('max_dd', 0):.2f}%")


def _regime_label(regime: str) -> str:
    """ãƒ¬ã‚¸ãƒ¼ãƒ ã®ãƒ©ãƒ™ãƒ«"""
    labels = {
        "uptrend": "ğŸ“ˆ Uptrend",
        "downtrend": "ğŸ“‰ Downtrend",
        "range": "â†”ï¸ Range",
        "all": "ğŸŒ All",
    }
    return labels.get(regime, regime)


def _template_label(template: str) -> str:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ©ãƒ™ãƒ«ï¼ˆçŸ­ç¸®å½¢ï¼‰"""
    if template in TEMPLATE_LABELS:
        return TEMPLATE_LABELS[template][0]
    return template
